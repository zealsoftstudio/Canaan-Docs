import{_ as o,r as l,o as d,c as p,d as n,w as i,b as t,e as s,a as e}from"./app-21fd3c9b.js";const c={},r=s('<h1 id="yolact模型部署实战" tabindex="-1"><a class="header-anchor" href="#yolact模型部署实战" aria-hidden="true">#</a> Yolact模型部署实战</h1><h2 id="_1-前言" tabindex="-1"><a class="header-anchor" href="#_1-前言" aria-hidden="true">#</a> 1 前言</h2><h3 id="_1-1-读者对象" tabindex="-1"><a class="header-anchor" href="#_1-1-读者对象" aria-hidden="true">#</a> 1.1 读者对象</h3><p>本文档（本指南）主要适用于以下人员：</p><p>• 技术支持工程师</p><p>• 软件开发工程师</p><p>• AI 应用案客户</p><h2 id="_2-正文" tabindex="-1"><a class="header-anchor" href="#_2-正文" aria-hidden="true">#</a> 2 正文</h2><h3 id="_2-1-npu-开发简介" tabindex="-1"><a class="header-anchor" href="#_2-1-npu-开发简介" aria-hidden="true">#</a> 2.1 NPU 开发简介</h3><p>• 支持int8/uint8/int16 量化精度，运算性能可达1TOPS.</p><p>• 相较于GPU 作为AI 运算单元的大型芯片方案，功耗不到GPU 所需要的1%.</p><p>• 可直接导入Caffe, TensorFlow, Onnx, TFLite，Keras, Darknet, pyTorch 等模型格式.</p><p>• 提供AI 开发工具：支持模型快速转换、支持开发板端侧转换API、支持TensorFlow, TF Lite, Caffe, ONNX, Darknet, pyTorch 等模型.</p><p>• 提供AI 应用开发接口：提供NPU 跨平台API.</p><h3 id="_2-2-开发流程" tabindex="-1"><a class="header-anchor" href="#_2-2-开发流程" aria-hidden="true">#</a> 2.2 开发流程</h3><p>NPU 开发完整的流程如下图所示：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208101012970.png" alt="image-20221208101012970"></p>',17),u=s('<h3 id="_2-3-获取yolact-原始模型" tabindex="-1"><a class="header-anchor" href="#_2-3-获取yolact-原始模型" aria-hidden="true">#</a> 2.3 获取YOLACT 原始模型</h3><p>YOLACT 模型获取方式有很多种，可以基于项目https://github.com/dbolya/yolact 产生onnx 格式的yolact 模型，本文档假设你已经产生了yolact.onnx 模型</p><h3 id="_2-4-模型部署工作目录结构" tabindex="-1"><a class="header-anchor" href="#_2-4-模型部署工作目录结构" aria-hidden="true">#</a> 2.4 模型部署工作目录结构</h3><p>yolact-sim.onnx 有120M，还是蛮大的.</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208101053708.png" alt="image-20221208101053708"></p>',5),_=s(`<h3 id="_2-5-导入模型" tabindex="-1"><a class="header-anchor" href="#_2-5-导入模型" aria-hidden="true">#</a> 2.5 导入模型</h3><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus import onnx --model yolact-sim.onnx --output-model yolact-sim.json --output-data yolact-sim.data
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>导入模型的目的是将开放模型转换为符合VIP 模型网络描述文件(.json) 和权重文件(.data)</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208101310404.png" alt="image-20221208101310404"></p>`,4),h=s(`<h3 id="_2-6-创建yml-文件" tabindex="-1"><a class="header-anchor" href="#_2-6-创建yml-文件" aria-hidden="true">#</a> 2.6 创建YML 文件</h3><p>YML 文件对网络的输入和输出进行描述，比如输入图像的形状，归一化系数(均值，零点)，图像格式，输出tensor 的输出格式，后处理方式等等，命令如下：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus generate inputmeta --model yolact-sim.json --input-meta-output yolact-sim-inputemeta.yml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus generate postprocess-file --model yolact-sim.json --postprocess-file-output yolact-simpostprocess-file.yml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208101601819.png" alt="image-20221208101601819"></p>`,5),m=e("p",null,"修改input meta 文件中的的scale 参数为0.0039(1/256)，和yolov3 的改法完全一致。",-1),g=e("p",null,[e("img",{src:"http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208101624198.png",alt:"image-20221208101624198"})],-1),v=s(`<h3 id="_2-7-量化" tabindex="-1"><a class="header-anchor" href="#_2-7-量化" aria-hidden="true">#</a> 2.7 量化</h3><p>量化命令：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus quantize --model yolact-sim.json --model-data yolact-sim.data --batch-size 1 --device CPU --with-input-meta yolact-sim-inputemeta.yml --rebuild --model-quantize yolact-sim.quantilize --quantizer asymmetric_affine --qtype uint8
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>命令执行后，创建了量化表文件</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208101701439.png" alt="image-20221208101701439"></p>`,5),y=s(`<h3 id="_2-8-预推理" tabindex="-1"><a class="header-anchor" href="#_2-8-预推理" aria-hidden="true">#</a> 2.8 预推理</h3><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus inference --model yolact-sim.json --model-data yolact-sim.data --batch-size 1 --dtype quantized --model-quantize yolact-sim.quantilize --device CPU --with-input-meta yolact-siminputemeta.yml --postprocess-file yolact-sim-postprocess-file.yml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208101802000.png" alt="image-20221208101802000"></p>`,3),x=s('<h3 id="_2-9-导出代码和nbg-文件" tabindex="-1"><a class="header-anchor" href="#_2-9-导出代码和nbg-文件" aria-hidden="true">#</a> 2.9 导出代码和NBG 文件</h3><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus export ovxlib --model yolact-sim.json --model-data yolact-sim.data --dtype quantized --model-quantize yolact-sim.quantilize --batch-size 1 --save-fused-graph --target-ide-project &#39;linux64&#39; --with-input-meta yolact-sim-inputemeta.yml --postprocess-file yolact-sim-postprocess-file.yml --output-path ovxlib/yolact/yolact --pack-nbg-unify --optimize &quot;VIP9000PICO_PID0XEE&quot; --vivsdk${VIV_SDK}\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus export ovxlib --model yolact-sim.json --model-data yolact-sim.data --dtype quantized --model-quantize yolact-sim.quantilize --batch-size 1 --save-fused-graph --target-ide-project &#39;linux64&#39; --with-input-meta yolact-sim-inputemeta.yml --postprocess-file yolact-sim-postprocess-file.yml --output-path ovxlib/yolact/yolact --pack-nbg-viplite --optimize &quot;VIP9000PICO_PID0XEE&quot; --vivsdk${VIV_SDK}\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208101926523.png" alt="image-20221208101926523"></p>',4),f=e("p",null,"生成的NBG 文件, 可以部署到端侧:",-1),b=e("p",null,[e("img",{src:"http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208101945583.png",alt:"image-20221208101945583"})],-1),A=s(`<h3 id="_2-10-模型算力测量" tabindex="-1"><a class="header-anchor" href="#_2-10-模型算力测量" aria-hidden="true">#</a> 2.10 模型算力测量</h3><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus measure --model yolact-sim.json
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208102008519.png" alt="image-20221208102008519"></p>`,3),I=e("p",null,"对比yolov3 的32.99G MACC 算力和yolov3-tiny 的2.79G macc 的算力需求，YOLACT 明显对算力的需求大很多. 题外话,1TOPS=1000GOPS, 对于yolov3-tiny 来",-1),k=e("p",null,"说，我们以3G 的算力需求来计算，就是0.003T，在500M 频率下，NPU 的理论算力是0.5T, 所以，YOLOV3 的帧率为：0.5T/0.003T=166 帧。这个值和仿真值是",-1),w=e("p",null,"比较接近的.",-1),z=e("h3",{id:"_2-11-后处理验证",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_2-11-后处理验证","aria-hidden":"true"},"#"),t(" 2.11 后处理验证")],-1),C=e("p",null,"yolact 的后处理C 代码在如下位置：",-1),P=e("p",null,[e("img",{src:"http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208102042389.png",alt:"image-20221208102042389"})],-1),q=e("p",null,"编译后处理模型:",-1),T=e("p",null,[e("img",{src:"http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208102206195.png",alt:"image-20221208102206195"})],-1),N=e("p",null,"out 目录生成了yolact 的后处理程序：",-1),O=e("p",null,[e("img",{src:"http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208102225653.png",alt:"image-20221208102225653"})],-1),V=e("p",null,"yolact 模型有五个输出层,inference 阶段生成了5 个output tensor.",-1),j=e("p",null,[e("img",{src:"http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208102753573.png",alt:"image-20221208102753573"})],-1),Y=e("p",null,"tensor之间的对应关系,0是location, 1是confidence, 2是mask，3暂时无用，4是maskmaps.",-1),D=e("p",null,"output0_4_19248_1.dat <---->iter_0_attach_Concat_Concat_256_out0_0_out0_1_19248_4.tensor",-1),G=e("p",null,"output1_81_19248_1.dat<---->iter_0_attach_Softmax_Softmax_260_out0_1_out0_1_19248_81.tensor",-1),L=e("p",null,"output2_32_19248_1.dat<---->iter_0_attach_Concat_Concat_258_out0_2_out0_1_19248_32.tensor",-1),S=e("p",null,"output3_4_19248.dat <---->iter_0_attach_Initializer_769_out0_3_out0_19248_4.tensor",-1),U=e("p",null,"output4_32_138_138_1.dat<---->iter_0_attach_Transpose_Transpose_165_out0_4_out0_1_138_138_32.tensor",-1),M=e("p",null,"执行后处理",-1),B=e("p",null,[e("img",{src:"http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208102833160.png",alt:"image-20221208102833160"})],-1),E=e("p",null,"后处理结果：",-1),F=e("p",null,[e("img",{src:"http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208102858625.png",alt:"image-20221208102858625"})],-1),K=e("p",null,"图中识别除了两只dog, 有两个狗的信息，其他都能很好的输出结果，dog 70.7% 不应该出现的，大概率是量化导致输出结果精度精度降低。",-1),X=e("p",null,"修改归一化参数后重新部署，得到的结果如下，可以看到，之前的问题消失：",-1),$=e("p",null,[e("img",{src:"http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20221208102920884.png",alt:"image-20221208102920884"})],-1),H=e("p",null,"至此，yoloact 模型导入完成.",-1),J=e("h3",{id:"_2-12-结束",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_2-12-结束","aria-hidden":"true"},"#"),t(" 2.12 结束")],-1);function Q(R,W){const a=l("center");return d(),p("div",null,[r,n(a,null,{default:i(()=>[t("图2-1: npu_1.png")]),_:1}),u,n(a,null,{default:i(()=>[t("图2-2: npu_workspace")]),_:1}),_,n(a,null,{default:i(()=>[t("图2-3: npu_import")]),_:1}),h,n(a,null,{default:i(()=>[t("图2-4: npu_yml")]),_:1}),m,g,n(a,null,{default:i(()=>[t("图2-5: npu_scale")]),_:1}),v,n(a,null,{default:i(()=>[t("图2-6: npu_quantilize")]),_:1}),y,n(a,null,{default:i(()=>[t("图2-7: npu_inf")]),_:1}),x,n(a,null,{default:i(()=>[t("图2-8: npu_export")]),_:1}),f,b,n(a,null,{default:i(()=>[t("图2-9: npu_nbg")]),_:1}),A,n(a,null,{default:i(()=>[t("图2-10: npu_measure")]),_:1}),I,k,w,z,C,P,n(a,null,{default:i(()=>[t("图2-11: npu_gerit")]),_:1}),q,T,n(a,null,{default:i(()=>[t("图2-12: npu_post")]),_:1}),N,O,n(a,null,{default:i(()=>[t("图2-13: npu_postprocess")]),_:1}),V,j,n(a,null,{default:i(()=>[t("图2-14: npu_tensor")]),_:1}),Y,D,G,L,S,U,M,B,n(a,null,{default:i(()=>[t("图2-15: npu_exepost")]),_:1}),E,F,n(a,null,{default:i(()=>[t("图2-16: npu_yolact")]),_:1}),K,X,$,n(a,null,{default:i(()=>[t("图2-17: npu_yolact_ok")]),_:1}),H,J])}const ee=o(c,[["render",Q],["__file","09-YolactModelDeploymentActualCombat.html.vue"]]);export{ee as default};
