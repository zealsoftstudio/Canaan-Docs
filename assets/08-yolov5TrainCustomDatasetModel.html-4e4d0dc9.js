import{_ as n,r as d,o as l,c as r,a,b as e,d as s,e as i}from"./app-21fd3c9b.js";const o={},p=a("h1",{id:"开发板端侧部署yolov5自定义模型",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#开发板端侧部署yolov5自定义模型","aria-hidden":"true"},"#"),e(" 开发板端侧部署YOLOV5自定义模型")],-1),c=a("h2",{id:"_0-前言",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#_0-前言","aria-hidden":"true"},"#"),e(" 0.前言")],-1),m={href:"https://forums.100ask.net/t/topic/3670",target:"_blank",rel:"noopener noreferrer"},g={href:"https://forums.100ask.net/t/topic/3648",target:"_blank",rel:"noopener noreferrer"},h=a("p",null,"​ 下面操作仅演示如何去训练自定义模型、导出模型、转换模型、模型部署。注意：训练模型对于电脑需要有一定的要求，如果电脑性能较弱可能会导致训练效果较差，从而导致模型精度较低。",-1),u={href:"https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/",target:"_blank",rel:"noopener noreferrer"},v=i('<h2 id="_1-下载数据标注工具" tabindex="-1"><a class="header-anchor" href="#_1-下载数据标注工具" aria-hidden="true">#</a> 1.下载数据标注工具</h2><p>数据标注工具：https://github.com/heartexlabs/labelImg/releases</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230628104416057.png" alt="image-20230628104416057"></p><p>点击上述红框下载，下载完成后解压压缩包，双击打开<code>labelImg.exe</code>文件。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230628104508751.png" alt="image-20230628104508751"></p><p>打开后等待运行，运行完成后会进入如下标注工作界面。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230628104644114.png" alt="image-20230628104644114"></p><p>关于LabelImg更多的使用方法，请访问：https://github.com/heartexlabs/labelImg</p><p>由于LabelImg会预先提供一些类供您使用，需要手动删除这些类，使得您可以标注自己的数据集。步骤如下所示：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/delete-labelImg-predefind.gif" alt="delete-labelImg-predefind"></p><p>进入LabelImg程序目录中的data目录中，打开<code>predefined_classes.txt</code>文件，删除文件中所有预定义的类后保存并退出即可。</p><h2 id="_2-创建数据集目录" tabindex="-1"><a class="header-anchor" href="#_2-创建数据集目录" aria-hidden="true">#</a> 2.创建数据集目录</h2><p>在任意工作目录中创建<code>images</code>文件夹和<code>labels</code>文件夹分别存放图像数据集和标注信息。这里我演示仅使用少量图像样本进行标注，在实际项目中需要采集足够的图像进行标注才拿满足模型的准确率和精度。</p><p>例如我在<code>100ask-yolov5-image</code>目录中创建有<code>images</code>文件夹和<code>labels</code>文件夹，如下所示，创建images文件，存放图像数据集，创建labels文件夹，该文件夹用于后续存放标注数据。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/DataSetworkingDirectory.gif" alt="DataSetworkingDirectory"></p><h2 id="_3-标注图像" tabindex="-1"><a class="header-anchor" href="#_3-标注图像" aria-hidden="true">#</a> 3.标注图像</h2><p>打开LabelImg软件后，使用软件打开数据集图像文件夹，如下所示：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/LabelImg-OpenDataSetDirectory.gif" alt="LabelImg-OpenDataSetDirectory"></p><p>打开后，修改输出label的文件夹为我们创建的数据集目录下的<code>labels</code>文件夹</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/LabelImg-changelabelDir.gif" alt="LabelImg-changelabelDir"></p><p>下面我演示标注过程，以百问网的开发板为例，标注三块开发板</p><p><img src="https://bbs.aw-ol.com/assets/uploads/files/1688096675613-labelimg-labelingprocess.gif" alt="label-iamge"></p><p>当你点击Save后即表示标注完成，标注完成后后会在<code>labels</code>目录下生成<code>classes.txt</code>（类别）和图像中标注的类别即位置信息。</p>',23),b={href:"https://github.com/heartexlabs/labelImg",target:"_blank",rel:"noopener noreferrer"},x=i(`<table><thead><tr><th>Ctrl + u</th><th>Load all of the images from a directory</th></tr></thead><tbody><tr><td>Ctrl + r</td><td>Change the default annotation target dir</td></tr><tr><td>Ctrl + s</td><td>Save</td></tr><tr><td>Ctrl + d</td><td>Copy the current label and rect box</td></tr><tr><td>Ctrl + Shift + d</td><td>Delete the current image</td></tr><tr><td>Space</td><td>Flag the current image as verified</td></tr><tr><td>w</td><td>Create a rect box</td></tr><tr><td>d</td><td>Next image</td></tr><tr><td>a</td><td>Previous image</td></tr><tr><td>del</td><td>Delete the selected rect box</td></tr><tr><td>Ctrl++</td><td>Zoom in</td></tr></tbody></table><p>经过标注大量的图像后，<code>labels</code>文件夹如下图所示</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/LabelImg-LabelsDir.gif" alt="LabelImg-LabelsDir"></p><h2 id="_4-划分训练集和验证集" tabindex="-1"><a class="header-anchor" href="#_4-划分训练集和验证集" aria-hidden="true">#</a> 4.划分训练集和验证集</h2><p>在模型训练中，需要有训练集和验证集。可以简单理解为网络使用训练集去训练，训练出来的网络使用验证集验证。在总数据集中训练集通常应占80%，验证集应占20%。所以将我们标注的数据集按比例进行分配。</p><p>​ 在yolov5-6.0项目目录下创建100ask文件夹（该文件夹名可自定义），在100ask文件夹中创建train文件夹（存放训练集）和创建val文件夹（存放验证集）</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-trainVal-Img.gif" alt="100ask-trainVal-Img"></p><p>​ 在train文件夹中创建images文件夹和labels文件夹。其中images文件夹存放总数据集的80%的图像文件，labels文件夹存放与images中的文件对应的标注文件。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-trainDir-ImgLab.gif" alt="100ask-trainDir-ImgLab"></p><p>​ 在val文件夹中创建images文件夹和labels文件夹。其中images文件夹存放总数据集的20%的图像文件，labels文件夹存放与images中的文件对应的标注文件。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-trainVal-Img.gif" alt="100ask-trainVal-Img"></p><h2 id="_5-创建数据集配置文件" tabindex="-1"><a class="header-anchor" href="#_5-创建数据集配置文件" aria-hidden="true">#</a> 5.创建数据集配置文件</h2><p>进入yolov5-6.0\\data目录下，创建<code>data.yaml</code>，文件内容如下所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>train: 100ask\\train\\images  # train images 
val: 100ask\\val\\images  # val images

nc: 3  # number of classes
names: [&#39;T113&#39;, &#39;K510&#39;, &#39;V853&#39;]  # class names
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-dataYaml-Config.gif" alt="100ask-dataYaml-Config"></p><h2 id="_6-创建模型配置文件" tabindex="-1"><a class="header-anchor" href="#_6-创建模型配置文件" aria-hidden="true">#</a> 6.创建模型配置文件</h2><p>进入models目录下，拷贝yolov5s.yaml文件，粘贴并models目录下重命名为100ask_my-model.yaml，例如：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-modelYaml-Config.gif" alt="100ask-modelYaml-Config"></p><p>修改100ask_my-model.yaml中类的数目为自己训练模型的类数目。</p><h2 id="_6-修改训练函数" tabindex="-1"><a class="header-anchor" href="#_6-修改训练函数" aria-hidden="true">#</a> 6.修改训练函数</h2><p>打开yolov5-6.0项目文件夹中的train.py，修改数据配置文件路径，如下图红框所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>parser.add_argument(&#39;--cfg&#39;, type=str, default=&#39;models/100ask_my-model.yaml&#39;, help=&#39;model.yaml path&#39;)
parser.add_argument(&#39;--data&#39;, type=str, default=ROOT / &#39;data/data.yaml&#39;, help=&#39;dataset.yaml path&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_7-训练模型" tabindex="-1"><a class="header-anchor" href="#_7-训练模型" aria-hidden="true">#</a> 7.训练模型</h2><p>在conda终端的激活yolov5环境，激活后进入yolov5-6.0项目文件夹。执行<code>python train.py</code>，如下图所示：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230628174332495.png" alt="image-20230628174332495"></p><p>程序默认迭代300次，等待训练完成...</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230628182753106.png" alt="image-20230628182753106"></p><p>训练完成后结果会保存在<code>runs\\train\\</code>目录下最新一次的训练结果，如上图所示，此次训练的最好模型和最后训练的模型保存在以下目录中</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>runs\\train\\exp7\\weights
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="_8-验证模型" tabindex="-1"><a class="header-anchor" href="#_8-验证模型" aria-hidden="true">#</a> 8.验证模型</h2><p>修改val.py函数，修改如下</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>    parser.add_argument(&#39;--data&#39;, type=str, default=ROOT / &#39;data/data.yaml&#39;, help=&#39;dataset.yaml path&#39;)
    parser.add_argument(&#39;--weights&#39;, nargs=&#39;+&#39;, type=str, default=ROOT / &#39;runs/train/exp7/weights/best.pt&#39;, help=&#39;model.pt path(s)&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230628183910971.png" alt="image-20230628183910971"></p><p>修改models文件夹下的yolo.py</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>class Model(nn.Module):
    def __init__(self, cfg=&#39;100ask_my-model.yaml&#39;, ch=3, nc=None, anchors=None):  # model, input channels, number of classes
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230628185921751.png" alt="image-20230628185921751"></p><p>打开conda终端输入<code>python val.py</code></p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230628190017879.png" alt="image-20230628190017879"></p><p>执行完成后的结果保存在<code>runs\\val\\exp</code>文件下。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-valRun.gif" alt="100ask-valRun"></p><h2 id="_9-预测图像" tabindex="-1"><a class="header-anchor" href="#_9-预测图像" aria-hidden="true">#</a> 9.预测图像</h2><p>在data目录中新建<code>100ask-images</code>文件夹存放待检测的图像和视频文件。</p><p>修改detect.py函数中，模型的路径与检测图像路径。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>parser.add_argument(&#39;--weights&#39;, nargs=&#39;+&#39;, type=str, default=ROOT / &#39;runs/train/exp7/weights/best.pt&#39;, help=&#39;model path(s)&#39;)
parser.add_argument(&#39;--source&#39;, type=str, default=ROOT / &#39;data/100ask-images&#39;, help=&#39;file/dir/URL/glob, 0 for webcam&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629103359183.png" alt="image-20230629103359183"></p><p>检测效果如下图所示：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/yolov5-detect.jpg" alt="2023-06-28 191541(3)"></p><h2 id="_10-导出onnx模型" tabindex="-1"><a class="header-anchor" href="#_10-导出onnx模型" aria-hidden="true">#</a> 10.导出ONNX模型</h2><p>修改export.py函数</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>parser.add_argument(&#39;--data&#39;, type=str, default=ROOT / &#39;data/data.yaml&#39;, help=&#39;dataset.yaml path&#39;)
parser.add_argument(&#39;--weights&#39;, type=str, default=ROOT / &#39;runs/train/exp7/weights/best.pt&#39;, help=&#39;weights path&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629103642324.png" alt="image-20230629103642324"></p><p>在conda终端输入：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>python export.py --include onnx --dynamic
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629104014942.png" alt="image-20230629104014942"></p><p>导出的模型会与输入的模型位于同一路径下，假设我输入的模型位于：<code>runs\\train\\exp7\\weights</code></p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629104123779.png" alt="image-20230629104123779"></p><h2 id="_11-简化模型" tabindex="-1"><a class="header-anchor" href="#_11-简化模型" aria-hidden="true">#</a> 11.简化模型</h2><p>简化模型前需要用到<code>onnxruntime</code>依赖包，输入以下命令安装：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pip install onnxruntime==1.13.1 -i https://pypi.doubanio.com/simple/
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>简化命令如下：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>python -m onnxsim &lt;输入模型&gt; &lt;输出模型&gt; --input-shape &lt;输入图像尺寸&gt;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>例如：</p><p>输入模型路径为runs/train/exp7/weights/best.onnx，输出模型路径为runs/train/exp7/weights/best-sim.onnx</p><p>输入图像尺寸固定为640x640。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>python -m onnxsim runs/train/exp7/weights/best.onnx runs/train/exp7/weights/best-sim.onnx --input-shape 1,3,640,640
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629110454569.png" alt="image-20230629110454569"></p><h2 id="_13-查看模型" tabindex="-1"><a class="header-anchor" href="#_13-查看模型" aria-hidden="true">#</a> 13.查看模型</h2><p>访问：https://netron.app/</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629111343751.png" alt="image-20230629111343751"></p><p>可以看到输入已经固定为640x640，可看到模型有 4 个输出节点，其中 ouput 节点为后处理解析后的节点；在实际测试的过程中，发现 NPU 量化操作后对后处理的运算非常不友好，输出数据偏差较大，所以我们可以将后处理部分放在 CPU 运行；因此在导入模型时保留 <code>350</code>，<code>498</code>， <code>646</code> 三个后处理解析前的输出节点即可。</p><h2 id="_14-验证模型" tabindex="-1"><a class="header-anchor" href="#_14-验证模型" aria-hidden="true">#</a> 14.验证模型</h2><p>模型需要修改为简化后的模型路径。</p><p>新建文件夹存放固定的输入图像尺寸。假设上述中我设置输入图像尺寸为640x640，那么此时我在data目录下新建100ask-images-640文件夹存放640x640的图像作为待测数据。</p><p>修改detect.py函数</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>    parser.add_argument(&#39;--weights&#39;, nargs=&#39;+&#39;, type=str, default=ROOT / &#39;runs/train/exp7/weights/best-sim.onnx&#39;, help=&#39;model path(s)&#39;)
    parser.add_argument(&#39;--source&#39;, type=str, default=ROOT / &#39;data/100ask-images-640&#39;, help=&#39;file/dir/URL/glob, 0 for webcam&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629112042899.png" alt="image-20230629112042899"></p><p>在conda终端输入：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>python detect.py
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629112859954.png" alt="image-20230629112859954"></p><p>通过输出信息可知：检测结果存储在runs\\detect\\exp6</p><p>检测结果如下：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/test-640.jpg" alt="test-640"></p><h2 id="_15-转换模型" tabindex="-1"><a class="header-anchor" href="#_15-转换模型" aria-hidden="true">#</a> 15.转换模型</h2><h3 id="_15-1-创建工作目录" tabindex="-1"><a class="header-anchor" href="#_15-1-创建工作目录" aria-hidden="true">#</a> 15.1 创建工作目录</h3><p>将简化后的<code>best-sim.onnx</code>模型传入配置到NPU模型转换工具的虚拟机中，创建模型工具目录，包含模型文件，量化文件夹<code>data</code>（存放量化图片），<code>dataset.txt</code>文件(存放量化图片的路径)。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>buntu@ubuntu2004:~/100ask-yolov5-test$ tree
.
├── best-sim.onnx
├── data
│   └── test01.jpg
└── dataset.txt

1 directory, 5 files
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>工作目录如下所示：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-changeModelDir.gif" alt="100ask-changeModelDir"></p><h3 id="_15-2-导入模型" tabindex="-1"><a class="header-anchor" href="#_15-2-导入模型" aria-hidden="true">#</a> 15.2 导入模型</h3><p>导入模型前需要知道我们要保留的输出节点，由之前查看到我们输出的三个后处理节点为：<code>350</code>，<code>498</code>，<code>646</code> 。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus import onnx --model best-sim.onnx --output-data best-sim.data --output-model best-sim.json --outputs &quot;350 498 646&quot;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>导入生成两个文件，分别是是 <code>yolov5s-sim.data</code> 和 <code>yolov5s-sim.json</code> 文件，两个文件是 YOLO V5 网络对应的芯原内部格式表示文件，<code>data</code> 文件储存权重，<code>cfg</code> 文件储存模型。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-leadingInmodel.gif" alt="100ask-leadingInmodel"></p><h3 id="_15-3-生成-yml-文件" tabindex="-1"><a class="header-anchor" href="#_15-3-生成-yml-文件" aria-hidden="true">#</a> 15.3 生成 YML 文件</h3><p>YML 文件对网络的输入和输出的超参数进行描述以及配置，这些参数包括，输入输出 tensor 的形状，归一化系数 (均值，零点)，图像格式，tensor 的输出格式，后处理方式等等</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus generate inputmeta --model best-sim.json --input-meta-output best-sim_inputmeta.yml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-generateModelInput.gif" alt="100ask-generateModelInput"></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus generate postprocess-file --model best-sim.json --postprocess-file-output best-sim_postprocess_file.yml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-generateModelOutput.gif" alt="100ask-generateModelOutput"></p><p>修改 <code>best-sim_inputmeta.yml</code> 文件中的的 <code>scale</code> 参数为 <code>0.0039216(1/255)</code>，目的是对输入 <code>tensor</code> 进行归一化，和网络进行训练的时候是对应的。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>vi best-sim_inputmeta.yml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>修改过程如下图所示：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-changeInputYaml.gif" alt="100ask-changeInputYaml"></p><h3 id="_15-4-量化" tabindex="-1"><a class="header-anchor" href="#_15-4-量化" aria-hidden="true">#</a> 15.4 量化</h3><p>生成量化表文件，使用非对称量化，uint8，修改 <code>--batch-size</code> 参数为你的 <code>dataset.txt</code> 里提供的图片数量。如果原始网络使用固定的batch_size，请使用固定的batch_size，如果原始网络使用可变batch_size，请将此参数设置为1。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus quantize --model best-sim.json --model-data best-sim.data --batch-size 1 --device CPU --with-input-meta best-sim_inputmeta.yml --rebuild --model-quantize best-sim.quantize --quantizer asymmetric_affine --qtype uint8
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-quantifyModel.gif" alt="100ask-quantifyModel"></p><h3 id="_15-5-预推理" tabindex="-1"><a class="header-anchor" href="#_15-5-预推理" aria-hidden="true">#</a> 15.5 预推理</h3><p>利用前文的量化表执行预推理，得到推理 <code>tensor</code></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus inference --model best-sim.json --model-data best-sim.data --batch-size 1 --dtype quantized --model-quantize best-sim.quantize --device CPU --with-input-meta best-sim_inputmeta.yml --postprocess-file best-sim_postprocess_file.yml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-PreInferenceModel.gif" alt="100ask-PreInferenceModel"></p><h3 id="_15-6-导出模板代码与模型" tabindex="-1"><a class="header-anchor" href="#_15-6-导出模板代码与模型" aria-hidden="true">#</a> 15.6 导出模板代码与模型</h3><p>输出的模型可以在 <code>ovxilb/100ask-best-sim_nbg_unify</code> 文件夹中找到<code>network_binary.nb</code>模型文件。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus export ovxlib --model best-sim.json --model-data best-sim.data --dtype quantized --model-quantize best-sim.quantize --batch-size 1 --save-fused-graph --target-ide-project &#39;linux64&#39; --with-input-meta best-sim_inputmeta.yml --output-path ovxilb/100ask-best-sim/100ask-simprj --pack-nbg-unify --postprocess-file best-sim_postprocessmeta.yml --optimize &quot;VIP9000PICO_PID0XEE&quot; --viv-sdk \${VIV_SDK}
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-Export-NBModel.gif" alt="100ask-Export-NBModel"></p><p>可以进入下图所示目录中将<code>network_binary.nb</code>模型文件拷贝出来备用。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-NBModelDir.gif" alt="100ask-NBModelDir"></p><h2 id="_16-端侧部署" tabindex="-1"><a class="header-anchor" href="#_16-端侧部署" aria-hidden="true">#</a> 16.端侧部署</h2>`,118),_={href:"https://forums.100ask.net/t/topic/3648",target:"_blank",rel:"noopener noreferrer"},k=a("code",null,"vnn_post_process.cpp",-1),f=i(`<h3 id="_16-1-修改draw-objects函数" tabindex="-1"><a class="header-anchor" href="#_16-1-修改draw-objects函数" aria-hidden="true">#</a> 16.1 修改<code>draw_objects</code>函数</h3><p>修改<code>draw_objects</code>函数中的类名，这里我训练的模型的类别分别是<code>T113、K510、V853</code></p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629180241351.png" alt="image-20230629180241351"></p><p>类别名称需要yolov5-6.0项目<code>data</code>目录下<code>data.yaml</code>对应</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629180515157.png" alt="image-20230629180515157"></p><h3 id="_16-2-修改generate-proposals函数" tabindex="-1"><a class="header-anchor" href="#_16-2-修改generate-proposals函数" aria-hidden="true">#</a> 16.2 修改<code>generate_proposals</code>函数</h3><p>修改<code>generate_proposals</code>函数中的类类别数量为您类别数量。假设我训练的类别总共有<code>T113、K510、V853</code>，这3个类别，修改为3即可。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629180707567.png" alt="image-20230629180707567"></p><p>修改后的文件如下所示：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/100ask-YOLOV5Dir.gif" alt="100ask-YOLOV5Dir"></p><h3 id="_16-3-编译" tabindex="-1"><a class="header-anchor" href="#_16-3-编译" aria-hidden="true">#</a> 16.3 编译</h3><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code> book@100ask:~/workspaces/tina-v853-open$ source build/envsetup.sh
 ...
 book@100ask:~/workspaces/tina-v853-open$ lunch
 ...1
 ...
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>进入menuconfig，输入</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code> make menuconfig
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>进入如下目录中，选中yolov5-100ask配置</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>&gt; 100ask 
	&gt; NPU
		&lt;*&gt; yolov5-100ask......................................... yolov5-100ask demo
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629185606559.png" alt="image-20230629185606559"></p><p>编译并生成镜像</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code> book@100ask:~/workspaces/tina-v853-open$ make
 ...
 book@100ask:~/workspaces/tina-v853-open$ pack
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>编译完成后使用全志烧写工具烧录镜像。</p><h3 id="_16-4-测试" tabindex="-1"><a class="header-anchor" href="#_16-4-测试" aria-hidden="true">#</a> 16.4 测试</h3><p><strong>主机端：</strong></p><p>​ 传入<code>640*640</code>的图像文件和<code>network_binary.nb</code>模型文件</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>book@100ask:~/workspaces/testImg$ adb push test-100ask.jpg /mnt/UDISK
test-100ask.jpg: 1 file pushed. 0.6 MB/s (51039 bytes in 0.078s)
book@100ask:~/workspaces/testImg$ adb push network_binary.nb /mnt/UDISK
network_binary.nb: 1 file pushed. 0.7 MB/s (7409024 bytes in 10.043s)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>开发板端：</strong></p><p>进入/mnt/UDISK/目录下</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>root@TinaLinux:/# cd /mnt/UDISK/
root@TinaLinux:/mnt/UDISK# ls
lost+found         network_binary.nb  overlay            test-100ask.jpg
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>运行yolov5检测程序</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>yolov5-100ask network_binary.nb test-100ask.jpg
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629190424474.png" alt="image-20230629190424474"></p><p>执行完成后会在当前目录下生成输出文件<code>yolov5_out.jpg</code></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>root@TinaLinux:/mnt/UDISK# ls
lost+found         overlay            yolov5_out.jpg
network_binary.nb  test-100ask.jpg
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>主机端：</strong></p><p>拉取开发板端的输出图像<code>yolov5_out.jpg</code></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>book@100ask:~/workspaces/testImg$ adb pull /mnt/UDISK/yolov5_out.jpg ./
/mnt/UDISK/yolov5_out.jpg: 1 file pulled. 0.8 MB/s (98685 bytes in 0.116s)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_17-检测效果图" tabindex="-1"><a class="header-anchor" href="#_17-检测效果图" aria-hidden="true">#</a> 17.检测效果图</h2><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629190722233.png" alt="image-20230629190722233"></p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629191417157.png" alt="image-20230629191417157"></p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230629191450619.png" alt="image-20230629191450619"></p>`,39);function y(A,I){const t=d("ExternalLinkIcon");return l(),r("div",null,[p,c,a("p",null,[e("​ 本章讲述如何训练自定义数据集生成模型，部署到100ASK-V853-PRO开发板上。这里假设您已经搭建好YOLOV5-V6.0的环境，搭建环境参考："),a("a",m,[e("YOLOV5-V6.0环境搭建"),s(t)]),e("。如果您没有阅读过"),a("a",g,[e("100ASK-V853-PRO开发板支持yolov5模型部署"),s(t)]),e("文章，请先按照这篇文章进行操作。")]),h,a("p",null,[e("参考链接："),a("a",u,[e("https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/"),s(t)])]),v,a("p",null,[e("下面为LabelImg"),a("a",b,[e("快捷键目录"),s(t)]),e("：")]),x,a("p",null,[e("这里引用上一篇《"),a("a",_,[e("100ASK-V853-PRO开发板支持yolov5模型部署"),s(t)]),e("》我们编写的yolov5端侧部署程序，这里进入端侧部署程序文件夹中拷贝一份新程序进行修改。主要修改"),k,e("程序。")]),f])}const O=n(o,[["render",y],["__file","08-yolov5TrainCustomDatasetModel.html.vue"]]);export{O as default};
