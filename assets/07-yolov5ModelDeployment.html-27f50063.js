import{_ as t,r as o,o as l,c as d,a as e,b as a,d as i,e as s}from"./app-21fd3c9b.js";const r={},p=s('<h1 id="开发板端侧部署yolov5模型" tabindex="-1"><a class="header-anchor" href="#开发板端侧部署yolov5模型" aria-hidden="true">#</a> 开发板端侧部署yolov5模型</h1><h2 id="_0-前言" tabindex="-1"><a class="header-anchor" href="#_0-前言" aria-hidden="true">#</a> 0.前言</h2><p>​ 本章节主要讲述如何获取yolov5单阶段目标检测算法，并将yolov5原始模型转换为ONNX格式。使用模型转换工具进行模型的转换，并将转换后的模型部署到开发板上。</p><p>​ 本章使用的软件列表：</p><ol><li>anaconda（Windows）</li><li>Git（Windows)</li><li>Tina SDK（Linux）</li><li>全志NPU扩展包（Linux）</li><li>OpenCV库（Linux）</li></ol>',5),c={href:"https://item.taobao.com/item.htm?&id=706864521673",target:"_blank",rel:"noopener noreferrer"},v={href:"https://forums.100ask.net/uploads/short-url/3EJbv6OUENwcKfBR5veOKWVMsey.zip",target:"_blank",rel:"noopener noreferrer"},u={href:"https://bbs.aw-ol.com/assets/uploads/files/1687760754902-v853_linux_100ask_uart0.img",target:"_blank",rel:"noopener noreferrer"},m=e("p",null,"YOLOV5官方提供的V6.0版本的资源：",-1),g={href:"https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.onnx",target:"_blank",rel:"noopener noreferrer"},h={href:"https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt",target:"_blank",rel:"noopener noreferrer"},b={href:"https://github.com/ultralytics/yolov5/archive/refs/tags/v6.0.zip",target:"_blank",rel:"noopener noreferrer"},x=e("h2",{id:"_1-配置yolov5环境",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_1-配置yolov5环境","aria-hidden":"true"},"#"),a(" 1.配置yolov5环境")],-1),y={href:"https://github.com/ultralytics/yolov5",target:"_blank",rel:"noopener noreferrer"},_=s(`<p>使用Git工具在任意目录下获取源码V6.0版本，输入</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>git clone -b v6.0 https://github.com/ultralytics/yolov5
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230613182944474.png" alt="image-20230613182944474"></p><p>如果您使用Git下载出现问题，也可以直接点击下面网址直接下载源码压缩包，下载完成解压即可正常使用。</p>`,4),f={href:"https://github.com/ultralytics/yolov5/archive/refs/tags/v6.0.zip",target:"_blank",rel:"noopener noreferrer"},k=s(`<p>等待下载完成，下载完成后会在当前目录下，查看到yolov5项目文件夹</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>100askTeam@DESKTOP-F46NFJT MINGW64 /d/Programmers/ModelDeployment/2.yolov5
$ ls
yolov5/

100askTeam@DESKTOP-F46NFJT MINGW64 /d/Programmers/ModelDeployment/2.yolov5
$ cd yolov5/

100askTeam@DESKTOP-F46NFJT MINGW64 /d/Programmers/ModelDeployment/2.yolov5/yolov5 (master)
$ ls
CITATION.cff     README.zh-CN.md  detect.py   requirements.txt  tutorial.ipynb
CONTRIBUTING.md  benchmarks.py    export.py   segment/          utils/
LICENSE          classify/        hubconf.py  setup.cfg         val.py
README.md        data/            models/     train.py
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>打开Anaconda Prompt (Anaconda3)软件，进入yolov5项目目录中，输入以下命令</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>(base) C:\\Users\\100askTeam&gt;D:

(base) D:\\&gt;cd D:\\Programmers\\ModelDeployment\\2.yolov5\\yolov5

(base) D:\\Programmers\\ModelDeployment\\2.yolov5\\yolov5&gt;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用conda创建yolov项目环境，输入</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>conda create -n my-yolov5-env python=3.7
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>激活yolov5环境</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>conda activate my-yolov5-env
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>安装依赖</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pip install -U -r requirements.txt -i https://pypi.doubanio.com/simple/
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230614111413244.png" alt="image-20230614111413244"></p><p><strong>FAQ：</strong></p><p>​ 搭建环境时由于版本的不同会遇各种问题，下面我会提供我配置好的环境所需的包文件版本，文件位于压缩包的requirements文件夹中的conda-yolov5_6-env.yaml。在Conda终端中创建新环境，执行</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>conda env create -f conda-yolov5_6-env.yaml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>执行<code>python detect.py</code>，测试环境是否搭建成功，执行后会自动下载模型权重文件</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230614115122455.png" alt="image-20230614115122455"></p>`,16),A={href:"https://github.com/ultralytics/yolov5/tree/v6.0",target:"_blank",rel:"noopener noreferrer"},w={href:"https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt",target:"_blank",rel:"noopener noreferrer"},I=s(`<p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230614144617406.png" alt="image-20230614144617406"></p><p>点进入后会进去yolov5资源中心，往下找到V6.0版本的资源下载界面，找到您所需的资源即可。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/yolov5-download.gif" alt="yolov5-download"></p><p>将该模型文件放在yolov5项目文件夹下，如下图所示：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230619162921742.png" alt="image-20230619162921742"></p><p>在conda终端中输入<code>python detect.py</code>，可得到如下执行结果</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>(my-yolov5-env) D:\\Programmers\\ModelDeployment\\2.yolov5\\yolov5-6.0&gt;python detect.py
detect: weights=yolov5s.pt, source=data\\images, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False
YOLOv5  2021-10-12 torch 2.0.1+cpu CPU

Fusing layers...
D:\\Anaconda3\\envs\\my-yolov5-env\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model Summary: 213 layers, 7225885 parameters, 0 gradients
image 1/2 D:\\Programmers\\ModelDeployment\\2.yolov5\\yolov5-6.0\\data\\images\\bus.jpg: 640x480 4 persons, 1 bus, Done. (0.274s)
image 2/2 D:\\Programmers\\ModelDeployment\\2.yolov5\\yolov5-6.0\\data\\images\\zidane.jpg: 384x640 2 persons, 1 tie, Done. (0.189s)
Speed: 4.5ms pre-process, 231.3ms inference, 2.8ms NMS per image at shape (1, 3, 640, 640)
Results saved to runs\\detect\\exp1
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>FAQ:</strong></p><p>​ 如果您执行此命令时，遇到如下报错：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230619161143601.png" alt="image-20230619161143601"></p><p>原因：torch版本过高，可以通过修改代码或者降低版本。</p><p>下面我使用修改代码的方式解决：</p><p>​ 修改<code>D:\\Anaconda3\\envs\\my-yolov5-env\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py</code>文件中的Upsample类中forward函数的返回值。</p><p>原本：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>    def forward(self, input: Tensor) -&gt; Tensor:
        return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners,
                             recompute_scale_factor=self.recompute_scale_factor)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>修改后：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>    def forward(self, input: Tensor) -&gt; Tensor:
        return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>修改结果如下图所示：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230619162245935.png" alt="image-20230619162245935"></p><p>执行<code>python detect.py</code>完成后，可以在yolov5项目文件夹下的runs\\detect\\exp1目录下找到执行后的输出结果，如下所示。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/bus.jpg" alt="bus"></p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/zidane.jpg" alt="zidane"></p><h2 id="_2-导出yolov5-onnx模型" tabindex="-1"><a class="header-anchor" href="#_2-导出yolov5-onnx模型" aria-hidden="true">#</a> 2.导出yolov5 ONNX模型</h2><h3 id="_2-1-export程序导出模型" tabindex="-1"><a class="header-anchor" href="#_2-1-export程序导出模型" aria-hidden="true">#</a> 2.1 export程序导出模型</h3><p>在export.py程序找到parse_opt函数，查看默认输出的模型格式。如果默认支持有onnx格式，就无需修改，如果默认没有填写onnx，修改默认格式为onnx格式。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230619163348744.png" alt="image-20230619163348744"></p><p>执行export.py函数前需要需要确保已经安装了onnx包，可手动安装，如下所示</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pip install onnx==1.13.0 -i https://pypi.doubanio.com/simple/
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230614143642210.png" alt="image-20230614143642210"></p><p>执行export.py函数导出yolov5的onnx格式动态模型，在conda终端输入</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>python export.py --weights yolov5s.pt --include onnx --dynamic
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230619164049085.png" alt="image-20230619164049085"></p><p>执行完成后会在yolov5项目目录中生成一个名称为<code>yolov5s.onnx</code>的文件，如下图所示：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230619164141069.png" alt="image-20230619164141069"></p><h3 id="_2-2-简化模型" tabindex="-1"><a class="header-anchor" href="#_2-2-简化模型" aria-hidden="true">#</a> 2.2 简化模型</h3><p>​ 由于转换的模型是动态 Shape 的，不限制输入图片的大小，对于 NPU 来说会增加处理工序，所以这里我们需要转换为静态 Shape 的模型。</p><p>​ 需要安装 <code>onnxsim</code> 工具，在conda终端输入</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pip install onnxsim -i https://pypi.doubanio.com/simple/
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230614145945598.png" alt="image-20230614145945598"></p><p>然后使用这条命令转换：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>python -m onnxsim yolov5s.onnx yolov5s-sim.onnx --input-shape 1,3,640,640
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230625153004215.png" alt="image-20230625153004215"></p><p>执行完成后会导出名为<code>yolov5s-sim.onnx</code>文件，文件位于yolov5项目文件夹下，如下图所示：</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230619164602355.png" alt="image-20230619164602355"></p><h3 id="_2-3-查看模型" tabindex="-1"><a class="header-anchor" href="#_2-3-查看模型" aria-hidden="true">#</a> 2.3 查看模型</h3><p>使用开源网站Netron网站</p>`,46),D={href:"https://netron.app/",target:"_blank",rel:"noopener noreferrer"},N=s(`<p>访问上面网址查看模型结构。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230619165052151.png" alt="image-20230619165052151"></p><p>选择<code>yolov5s-sim.onnx</code>文件，点击打开。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230619165209306.png" alt="image-20230619165209306"></p><p>查看如下图所示输出节点</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230625153134978.png" alt="image-20230625153134978"></p><p>可看到模型有 4 个输出节点，其中 ouput 节点为后处理解析后的节点；在实际测试的过程中，发现 NPU 量化操作后对后处理的运算非常不友好，输出数据偏差较大，所以我们可以将后处理部分放在 CPU 运行；因此保留 <code>350</code>，<code>498</code>，<code>646</code> 三个后处理解析前的输出节点即可，后文在导入模型时修改输出节点。</p><h2 id="_3-转换npu模型" tabindex="-1"><a class="header-anchor" href="#_3-转换npu模型" aria-hidden="true">#</a> 3.转换NPU模型</h2><h3 id="_3-1-创建转换目录" tabindex="-1"><a class="header-anchor" href="#_3-1-创建转换目录" aria-hidden="true">#</a> 3.1 创建转换目录</h3><p>​ 打开NPU工具包的虚拟机Ubuntu20.04，创建yolov5-6.0文件夹，存放模型和量化图像等。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~$ mkdir yolov5-6.0
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>进入yolov5模型转换目录。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~$ cd yolov5-6.0/
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>创建data目录存放量化图像</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>mkdir data
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>将量化图像传入data文件夹下，例如，传入<code>test01.jpg</code>图像到<code>data</code></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~/yolov5-test$ ls data
test01.jpg
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>在yolov5模型转换目录中创建<code>dataset.txt</code></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~/yolov5-6.0$ touch dataset.txt 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>修改<code>dataset.txt</code>文件</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~/yolov5-6.0$ vi dataset.txt
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>在<code>dataset.txt</code>文件中增加量化图片的路径.</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>./data/test01.jpg
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230619175830410.png" alt="image-20230619175830410"></p><p>将<code>yolov5s-sim.onnx</code>模型传入yolov5模型转换文件夹下。例如：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~/yolov5-6.0$ ls
data  dataset.txt  yolov5s-sim.onnx
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>工作目录的文件如下所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~/yolov5-6.0$ tree
.
├── data
│   └── test01.jpg
├── dataset.txt
└── yolov5s-sim.onnx

1 directory, 3 files
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_3-2-导入模型" tabindex="-1"><a class="header-anchor" href="#_3-2-导入模型" aria-hidden="true">#</a> 3.2 导入模型</h3><p>导入模型前需要知道我们要保留的输出节点，由之前查看到我们输出的三个后处理节点为：<code>350</code>，<code>498</code>，<code>646</code> 。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus import onnx --model yolov5s-sim.onnx --output-data yolov5s-sim.data --output-model yolov5s-sim.json --outputs 350 498 646
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>导入生成两个文件，分别是是 <code>yolov5s-sim.data</code> 和 <code>yolov5s-sim.json</code> 文件，两个文件是 YOLO V5 网络对应的芯原内部格式表示文件，<code>data</code> 文件储存权重，<code>cfg</code> 文件储存模型。</p><h3 id="_3-3生成-yml-文件" tabindex="-1"><a class="header-anchor" href="#_3-3生成-yml-文件" aria-hidden="true">#</a> 3.3生成 YML 文件</h3><p>YML 文件对网络的输入和输出的超参数进行描述以及配置，这些参数包括，输入输出 tensor 的形状，归一化系数 (均值，零点)，图像格式，tensor 的输出格式，后处理方式等等</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus generate inputmeta --model yolov5s-sim.json --input-meta-output yolov5s-sim_inputmeta.yml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230619181406282.png" alt="image-20230619181406282"></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus generate postprocess-file --model yolov5s-sim.json --postprocess-file-output yolov5s-sim_postprocess_file.yml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>修改 <code>yolov5s-sim_inputmeta.yml</code> 文件中的的 <code>scale</code> 参数为 <code>0.0039216(1/255)</code>，目的是对输入 <code>tensor</code> 进行归一化，和网络进行训练的时候是对应的。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>vi yolov5s-sim_inputmeta.yml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230621183150357.png" alt="image-20230621183150357"></p><h3 id="_3-4-量化" tabindex="-1"><a class="header-anchor" href="#_3-4-量化" aria-hidden="true">#</a> 3.4 量化</h3><p>生成量化表文件，使用非对称量化，uint8，修改 <code>--batch-size</code> 参数为你的 <code>dataset.txt</code> 里提供的图片数量。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus quantize --model yolov5s-sim.json --model-data yolov5s-sim.data --batch-size 1 --device CPU --with-input-meta yolov5s-sim_inputmeta.yml --rebuild --model-quantize yolov5s-sim.quantize --quantizer asymmetric_affine --qtype uint8
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230619181548262.png" alt="image-20230619181548262"></p><h3 id="_3-5-预推理" tabindex="-1"><a class="header-anchor" href="#_3-5-预推理" aria-hidden="true">#</a> 3.5 预推理</h3><p>利用前文的量化表执行预推理，得到推理 <code>tensor</code></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus inference --model yolov5s-sim.json --model-data yolov5s-sim.data --batch-size 1 --dtype quantized --model-quantize yolov5s-sim.quantize --device CPU --with-input-meta yolov5s-sim_inputmeta.yml --postprocess-file yolov5s-sim_postprocess_file.yml
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230619181729205.png" alt="image-20230619181729205"></p><h3 id="_3-6-导出模板代码与模型" tabindex="-1"><a class="header-anchor" href="#_3-6-导出模板代码与模型" aria-hidden="true">#</a> 3.6 导出模板代码与模型</h3><p>输出的模型可以在 <code>ovxilb/yolov5s-sim_nbg_unify</code> 文件夹中找到<code>network_binary.nb</code>文件。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pegasus export ovxlib --model yolov5s-sim.json --model-data yolov5s-sim.data --dtype quantized --model-quantize yolov5s-sim.quantize --batch-size 1 --save-fused-graph --target-ide-project &#39;linux64&#39; --with-input-meta yolov5s-sim_inputmeta.yml --output-path ovxilb/yolov5s-sim/yolov5s-simprj --pack-nbg-unify --postprocess-file yolov5s-sim_postprocessmeta.yml --optimize &quot;VIP9000PICO_PID0XEE&quot; --viv-sdk \${VIV_SDK}
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230619181923864.png" alt="image-20230619181923864"></p><p>将生成的<code>network_binary.nb</code>文件拷贝出来备用。</p><h2 id="_4-yolov5端侧部署" tabindex="-1"><a class="header-anchor" href="#_4-yolov5端侧部署" aria-hidden="true">#</a> 4.YOLOV5端侧部署</h2><h3 id="_4-1-配置yolov5端侧部署环境" tabindex="-1"><a class="header-anchor" href="#_4-1-配置yolov5端侧部署环境" aria-hidden="true">#</a> 4.1 配置yolov5端侧部署环境</h3><p>​ 在进行端侧部署前，由于后处理需要使用OpenCV库，所以请先按照如下步骤</p><ul><li><p>配置NPU拓展包：https://forums.100ask.net/t/topic/3224</p></li><li><p>配置OpenCV库：https://forums.100ask.net/t/topic/3349</p><p>配置完成后才能编译端侧部署程序。</p></li></ul><p>​ 下载<code>source</code>压缩包中的<code>yolov5.tar.gz</code>，将该压缩包拷贝到虚拟机中，解压压缩包</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>tar -xzvf yolov5.tar.gz
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>将解压出来的文件夹拷贝到<code>tina-v853-open/openwrt/package/npu/</code>目录下</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>cp yolov5/ ~/workspaces/tina-v853-open/openwrt/package/npu/ -rf
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>注意：上面的<code>~/workspaces/tina-v853-open/openwrt/package/npu/</code>目录需要更换为您自己的SDK实际的目录。</p><p>拷贝完成后，如下所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>book@100ask:~/workspaces/tina-v853-open/openwrt/package/npu$ ls
lenet  viplite-driver  vpm_run  yolov3  yolov5
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-2-编译端侧部署代码" tabindex="-1"><a class="header-anchor" href="#_4-2-编译端侧部署代码" aria-hidden="true">#</a> 4.2 编译端侧部署代码</h3><p>配置编译环境</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>book@100ask:~/workspaces/tina-v853-open$ source build/envsetup.sh 
...
book@100ask:~/workspaces/tina-v853-open$ lunch

You&#39;re building on Linux

Lunch menu... pick a combo:
     1  v853-100ask-tina
     2  v853-vision-tina
Which would you like? [Default v853-100ask]: 1
...
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>进入Tina配置界面</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>book@100ask:~/workspaces/tina-v853-open$ make menuconfig
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>进入如下目录，选中yolov5后即可编译端侧部署程序</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>&gt; 100ask 
	&gt; NPU 
		&lt;*&gt; yolov5....................................................... yolov5 demo             
		&lt;*&gt;   yolov5-model...................................... yolov5 test demo model
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>注意：yolov5-model该选择后会将yolov5_model.nb打包进镜像中，该模型文件会在/etc/models/目录下。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230625170009845.png" alt="image-20230625170009845"></p><p>保存并退出Tina配置界面。</p><p>编译Tina SDK镜像，编译完成后打包生成镜像</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>book@100ask:~/workspaces/tina-v853-open$ make
...
book@100ask:~/workspaces/tina-v853-open$ pack
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>注意：如果您将模型打包进镜像中，可能会出现文件系统大小设置值太小的问题们可以参考https://forums.100ask.net/t/topic/3158解决。</p><p>打包完成后，使用全志烧写工具进行烧写新镜像，如果您还不会烧写系统，请参考：https://forums.100ask.net/t/topic/3403</p><h3 id="_4-3-测试yolov5端侧部署" tabindex="-1"><a class="header-anchor" href="#_4-3-测试yolov5端侧部署" aria-hidden="true">#</a> 4.3 测试yolov5端侧部署</h3><p>测试图像文件要求：</p><ul><li>图片</li><li>尺寸：640*640</li></ul><p><strong>开发板端：</strong></p><p>​ 使用ADB将测试图片传输到开发板上，将USB0的模式切换到 Device 模式</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>cat /sys/devices/platform/soc/usbc0/usb_device
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230625171158725.png" alt="image-20230625171158725"></p><p><strong>主机端：</strong></p><p>将ADB设备连接上虚拟机，并将虚拟机中的测试图片传输到开发板中，查看ADB设备</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>book@100ask:~/workspaces/testImg$ adb devices
List of devices attached
20080411	device
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>查看需要传输的文件</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>book@100ask:~/workspaces/testImg$ ls bus_640-640.jpg 
bus_640-640.jpg
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>传输文件到开发板中</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>book@100ask:~/workspaces/testImg$ adb push bus_640-640.jpg /mnt/UDISK
bus_640-640.jpg: 1 file pushed. 0.7 MB/s (97293 bytes in 0.128s)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>开发板端：</strong></p><p>进入测试图像目录</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>root@TinaLinux:/# cd /mnt/UDISK/
root@TinaLinux:/mnt/UDISK# ls
bus_640-640.jpg  lost+found       overlay
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>yolov5程序参数要求：yolov5 &lt;模型文件路径&gt; &lt;测试图像路径&gt;</p><p>如果您打包了默认的yolov5模型文件，可以输入</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>yolov5 /etc/models/yolov5_model.nb ./bus_640-640.jpg
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>如果您需要选择自己的模型文件进行测试，可以将上面的<code>/etc/models/yolov5_model.nb</code>更换为自己的模型路径，下面我以默认的模型文件进行测试。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230625172157448.png" alt="image-20230625172157448"></p><p>查看输出图像文件<code>yolov5_out.jpg</code></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>root@TinaLinux:/mnt/UDISK# ls 
bus_640-640.jpg  lost+found       overlay          yolov5_out.jpg
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>主机端：</strong></p><p>拉取输出文件<code>yolov5_out.jpg</code>到当前文件夹下</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>book@100ask:~/workspaces/testImg$ adb pull /mnt/UDISK/yolov5_out.jpg ./
/mnt/UDISK/yolov5_out.jpg: 1 file pulled. 0.9 MB/s (184894 bytes in 0.202s)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230625172512521.png" alt="image-20230625172512521"></p><h3 id="_4-4-测试其他图像" tabindex="-1"><a class="header-anchor" href="#_4-4-测试其他图像" aria-hidden="true">#</a> 4.4 测试其他图像</h3><p>对于人形的识别，该模型还是比较准确的</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230625175804726.png" alt="image-20230625175804726"></p><p>对于交通道路这种复杂的情况，对于行人丢失些许目标，但对于车辆效果很好，丢失情况较少。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230625180437728.png" alt="image-20230625180437728"></p><p>测试动物，对于动物的检测该模型是十分准确的，检测效果即预测精度都较高。</p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230625181808524.png" alt="image-20230625181808524"></p><p><img src="http://photos.100ask.net/allwinner-docs/v853/AIApplication/image-20230625184657791.png" alt="image-20230625184657791"></p>`,114);function z(j,T){const n=o("ExternalLinkIcon");return l(),d("div",null,[p,e("p",null,[a("硬件列表： 百问网100ASK_V853-PRO开发板："),e("a",c,[a("https://item.taobao.com/item.htm?&id=706864521673"),i(n)])]),e("p",null,[a("这里提供Source资源包："),e("a",v,[a("source"),i(n)]),a("（包含conda配置yolov5环境依赖包文件，端侧部署代码）")]),e("p",null,[a("yolov5体验镜像："),e("a",u,[a("v853_linux_100ask_uart0.img"),i(n)]),a(" （测试方法：yolov5 /etc/models/yolov5_model.nb <测试图像>）")]),m,e("p",null,[a("yolov5s ONNX模型文件："),e("a",g,[a("https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.onnx"),i(n)])]),e("p",null,[a("yolov5s PT模型文件："),e("a",h,[a("https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt"),i(n)])]),e("p",null,[a("yolov5-v6.0代码："),e("a",b,[a("https://github.com/ultralytics/yolov5/archive/refs/tags/v6.0.zip"),i(n)])]),x,e("p",null,[a("yolov5官方网址为："),e("a",y,[a("https://github.com/ultralytics/yolov5"),i(n)])]),_,e("p",null,[e("a",f,[a("https://github.com/ultralytics/yolov5/archive/refs/tags/v6.0.zip"),i(n)])]),k,e("p",null,[a("这里下载速度可能会很慢，建议直接访问官网下载"),e("a",A,[a("https://github.com/ultralytics/yolov5/tree/v6.0"),i(n)]),a("，点击下图红框处的YOLOV5s。这里我下载 v6.0 版本的 yolov5s.onnx 模型作为示例。")]),e("p",null,[a("下载地址："),e("a",w,[a("https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt"),i(n)])]),I,e("p",null,[e("a",D,[a("https://netron.app/"),i(n)])]),N])}const F=t(r,[["render",z],["__file","07-yolov5ModelDeployment.html.vue"]]);export{F as default};
