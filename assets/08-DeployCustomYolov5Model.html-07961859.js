import{_ as d,r as s,o,c as l,a,b as e,d as n,e as i}from"./app-21fd3c9b.js";const c={},r=i('<h1 id="yolov5训练自定义模型部署" tabindex="-1"><a class="header-anchor" href="#yolov5训练自定义模型部署" aria-hidden="true">#</a> YOLOV5训练自定义模型部署</h1><p><strong>PC主机端要求：</strong></p><ul><li>显卡，显存4GB以上（无显卡，纯CPU训练较慢）</li><li>内存16GB以上</li><li>硬盘100GB以上（建议200GB以上）</li><li>系统：Windows10/11系统</li></ul><p><strong>开发板端侧硬件要求：</strong></p><ul><li>DongshanPI-Vision开发板（搭载嘉楠K510芯片）</li><li>MIPI摄像头 x2</li><li>MIPI显示屏</li><li>Type-C数据线 x2 /电池供电</li></ul><p><strong>软件要求：</strong></p>',6),u={href:"https://www.anaconda.com/",target:"_blank",rel:"noopener noreferrer"},m={href:"https://www.jetbrains.com/pycharm/",target:"_blank",rel:"noopener noreferrer"},p={href:"https://github.com/heartexlabs/labelImg/releases",target:"_blank",rel:"noopener noreferrer"},v=a("p",null,"开始前请注意：",-1),b={href:"https://github.com/ultralytics/yolov5/archive/refs/tags/v6.0.zip",target:"_blank",rel:"noopener noreferrer"},_={href:"https://dongshanpi.cowtransfer.com/s/48f51cc100844b",target:"_blank",rel:"noopener noreferrer"},h=a("h2",{id:"_1-训练自定义模型",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#_1-训练自定义模型","aria-hidden":"true"},"#"),e(" 1.训练自定义模型")],-1),g=a("h3",{id:"_1-1-下载标注工具",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#_1-1-下载标注工具","aria-hidden":"true"},"#"),e(" 1.1 下载标注工具")],-1),x={href:"https://github.com/tzutalin/labelImg/files/2638199/windows_v1.8.1.zip",target:"_blank",rel:"noopener noreferrer"},f=i('<p>下载完成后解压压缩包，进入<code>windows_v1.8.1</code>文件夹下双击打开<code>labelImg.exe</code>文件。</p><p><img src="http://photos.100ask.net/canaan-docs/image-20230628104508751.png" alt="image-20230628104508751"></p><p>打开后等待运行，运行完成后会进入如下标注工作界面。</p><p><img src="http://photos.100ask.net/canaan-docs/image-20230628104644114.png" alt="image-20230628104644114"></p><p>关于LabelImg更多的使用方法，请访问：https://github.com/heartexlabs/labelImg</p><p><strong>注意</strong>：由于LabelImg会预先提供一些类供您使用，需要手动删除这些类，使得您可以标注自己的数据集。步骤如下所示：</p><p>在<code>windows_v1.8.1</code>文件夹进入data目录中，可以看到有一个名为<code>predefined_classes.txt</code>文件，里面预先定义了一些类，如果里面定义的类您不需要可将该文件里的全部类删除，操作过程如下所示：</p><p><img src="http://photos.100ask.net/canaan-docs/delete-labelImg-predefind.gif" alt="delete-labelImg-predefind"></p><h3 id="_1-2-创建数据集目录" tabindex="-1"><a class="header-anchor" href="#_1-2-创建数据集目录" aria-hidden="true">#</a> 1.2 创建数据集目录</h3><p>在任意工作目录中创建<code>images</code>文件夹和<code>labels</code>文件夹分别存放图像数据集和标注信息。这里我演示仅使用少量图像样本进行标注，在实际项目中需要采集足够的图像进行标注才拿满足模型的准确率和精度。</p><p>例如我在<code>100ask-yolov5-image</code>目录中创建有<code>images</code>文件夹和<code>labels</code>文件夹，如下所示，创建images文件，存放图像数据集，创建labels文件夹，该文件夹用于后续存放标注数据。</p><p><img src="http://photos.100ask.net/canaan-docs/DataSetworkingDirectory.gif" alt="DataSetworkingDirectory"></p><h3 id="_1-3-标注图像" tabindex="-1"><a class="header-anchor" href="#_1-3-标注图像" aria-hidden="true">#</a> 1.3 标注图像</h3><p>打开LabelImg软件后，使用软件打开数据集图像文件夹，如下所示：</p><p><img src="http://photos.100ask.net/canaan-docs/LabelImg-OpenDataSetDirectory.gif" alt="LabelImg-OpenDataSetDirectory"></p><p>打开后，修改输出label的文件夹为我们创建的数据集目录下的<code>labels</code>文件夹</p><p><img src="http://photos.100ask.net/canaan-docs/LabelImg-changelabelDir.gif" alt="LabelImg-changelabelDir"></p><p>下面我演示标注过程，以百问网的开发板为例，标注三块开发板</p><p><img src="http://photos.100ask.net/canaan-docs/LabelImg-LabelingProcess.gif" alt="LabelImg-LabelingProcess"></p><p>当你点击Save后即表示标注完成，标注完成后后会在<code>labels</code>目录下生成<code>classes.txt</code>（类别）和图像中标注的类别即位置信息。</p>',20),k={href:"https://github.com/heartexlabs/labelImg",target:"_blank",rel:"noopener noreferrer"},q=i('<table><thead><tr><th>Ctrl + u</th><th>Load all of the images from a directory</th></tr></thead><tbody><tr><td>Ctrl + r</td><td>Change the default annotation target dir</td></tr><tr><td>Ctrl + s</td><td>Save</td></tr><tr><td>Ctrl + d</td><td>Copy the current label and rect box</td></tr><tr><td>Ctrl + Shift + d</td><td>Delete the current image</td></tr><tr><td>Space</td><td>Flag the current image as verified</td></tr><tr><td>w</td><td>Create a rect box</td></tr><tr><td>d</td><td>Next image</td></tr><tr><td>a</td><td>Previous image</td></tr><tr><td>del</td><td>Delete the selected rect box</td></tr><tr><td>Ctrl++</td><td>Zoom in</td></tr></tbody></table><p>经过标注大量的图像后，<code>labels</code>文件夹如下图所示</p><p><img src="http://photos.100ask.net/canaan-docs/LabelImg-LabelsDir.gif" alt="LabelImg-LabelsDir"></p><h3 id="_1-4-划分训练集和验证集" tabindex="-1"><a class="header-anchor" href="#_1-4-划分训练集和验证集" aria-hidden="true">#</a> 1.4 划分训练集和验证集</h3>',4),y={href:"https://dongshanpi.cowtransfer.com/s/a8d5f9b4faec4c",target:"_blank",rel:"noopener noreferrer"},j=i(`<p>​ 在模型训练中，需要有训练集和验证集。可以简单理解为网络使用训练集去训练，训练出来的网络使用验证集验证。在总数据集中训练集通常应占80%，验证集应占20%。所以将我们标注的数据集按比例进行分配。</p><p>​ 在yolov5-6.0项目目录下创建100ask文件夹（该文件夹名可自定义），在100ask文件夹中创建train文件夹（存放训练集）和创建val文件夹（存放验证集）</p><p><img src="http://photos.100ask.net/canaan-docs/100ask-trainVal-Img.gif" alt="100ask-trainVal-Img"></p><p>​ 在train文件夹中创建images文件夹和labels文件夹。其中images文件夹存放总数据集的80%的图像文件，labels文件夹存放与images中的文件对应的标注文件。</p><p><img src="http://photos.100ask.net/canaan-docs/100ask-trainDir-ImgLab.gif" alt="100ask-trainDir-ImgLab"></p><p>​ 在val文件夹中创建images文件夹和labels文件夹。其中images文件夹存放总数据集的20%的图像文件，labels文件夹存放与images中的文件对应的标注文件。</p><p><img src="http://photos.100ask.net/canaan-docs/100ask-trainVal-Img.gif" alt="100ask-trainVal-Img"></p><h3 id="_1-5-创建数据集配置文件" tabindex="-1"><a class="header-anchor" href="#_1-5-创建数据集配置文件" aria-hidden="true">#</a> 1.5 创建数据集配置文件</h3><p>进入yolov5-6.0\\data目录下，创建<code>data.yaml</code>，文件内容如下所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>train: 100ask\\train\\images  # train images 
val: 100ask\\val\\images  # val images

nc: 3  # number of classes
names: [&#39;T113&#39;, &#39;K510&#39;, &#39;V853&#39;]  # class names
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/canaan-docs/100ask-dataYaml-Config.gif" alt="100ask-dataYaml-Config"></p><h3 id="_1-6-创建模型配置文件" tabindex="-1"><a class="header-anchor" href="#_1-6-创建模型配置文件" aria-hidden="true">#</a> 1.6 创建模型配置文件</h3><p>进入models目录下，拷贝yolov5s.yaml文件，粘贴并models目录下重命名为100ask_my-model.yaml，例如：</p><p><img src="http://photos.100ask.net/canaan-docs/100ask-modelYaml-Config.gif" alt="100ask-modelYaml-Config"></p><p>修改100ask_my-model.yaml中类的数目为自己训练模型的类数目。</p><h3 id="_1-6-修改训练函数" tabindex="-1"><a class="header-anchor" href="#_1-6-修改训练函数" aria-hidden="true">#</a> 1.6 修改训练函数</h3><p>打开yolov5-6.0项目文件夹中的train.py，修改数据配置文件路径，如下图红框所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>parser.add_argument(&#39;--cfg&#39;, type=str, default=&#39;models/100ask_my-model.yaml&#39;, help=&#39;model.yaml path&#39;)
parser.add_argument(&#39;--data&#39;, type=str, default=ROOT / &#39;data/data.yaml&#39;, help=&#39;dataset.yaml path&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_1-7-训练模型" tabindex="-1"><a class="header-anchor" href="#_1-7-训练模型" aria-hidden="true">#</a> 1.7 训练模型</h3><p>在conda终端的激活yolov5环境，激活后进入yolov5-6.0项目文件夹。执行<code>python train.py</code>，如下图所示：</p><p><img src="http://photos.100ask.net/canaan-docs/image-20230628174332495.png" alt="image-20230628174332495"></p><p>程序默认迭代300次，等待训练完成...</p><p><img src="http://photos.100ask.net/canaan-docs/image-20230628182753106.png" alt="image-20230628182753106"></p><p>训练完成后结果会保存在<code>runs\\train\\</code>目录下最新一次的训练结果，如上图所示，此次训练的最好模型和最后训练的模型保存在以下目录中</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>runs\\train\\exp7\\weights
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="_1-8-验证模型" tabindex="-1"><a class="header-anchor" href="#_1-8-验证模型" aria-hidden="true">#</a> 1.8 验证模型</h3><p>修改val.py函数，修改如下</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>    parser.add_argument(&#39;--data&#39;, type=str, default=ROOT / &#39;data/data.yaml&#39;, help=&#39;dataset.yaml path&#39;)
    parser.add_argument(&#39;--weights&#39;, nargs=&#39;+&#39;, type=str, default=ROOT / &#39;runs/train/exp7/weights/best.pt&#39;, help=&#39;model.pt path(s)&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/canaan-docs/image-20230628183910971.png" alt="image-20230628183910971"></p><p>修改models文件夹下的yolo.py</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>class Model(nn.Module):
    def __init__(self, cfg=&#39;100ask_my-model.yaml&#39;, ch=3, nc=None, anchors=None):  # model, input channels, number of classes
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/canaan-docs/image-20230628185921751.png" alt="image-20230628185921751"></p><p>打开conda终端输入<code>python val.py</code></p><p><img src="http://photos.100ask.net/canaan-docs/image-20230628190017879.png" alt="image-20230628190017879"></p><p>执行完成后的结果保存在<code>runs\\val\\exp</code>文件下。</p><p><img src="http://photos.100ask.net/canaan-docs/100ask-valRun.gif" alt="100ask-valRun"></p><h3 id="_1-9-预测图像" tabindex="-1"><a class="header-anchor" href="#_1-9-预测图像" aria-hidden="true">#</a> 1.9 预测图像</h3><p>在data目录中新建<code>100ask-images</code>文件夹存放待检测的图像和视频文件。</p><p>修改detect.py函数中，模型的路径与检测图像路径。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>parser.add_argument(&#39;--weights&#39;, nargs=&#39;+&#39;, type=str, default=ROOT / &#39;runs/train/exp7/weights/best.pt&#39;, help=&#39;model path(s)&#39;)
parser.add_argument(&#39;--source&#39;, type=str, default=ROOT / &#39;data/100ask-images&#39;, help=&#39;file/dir/URL/glob, 0 for webcam&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/canaan-docs/image-20230629103359183.png" alt="image-20230629103359183"></p><p>检测效果如下图所示：</p><p><img src="http://photos.100ask.net/canaan-docs/yolov5-detect.jpg" alt="yolov5-detect"></p><h2 id="_2-导出和转换模型" tabindex="-1"><a class="header-anchor" href="#_2-导出和转换模型" aria-hidden="true">#</a> 2.导出和转换模型</h2>`,44),C={href:"https://dongshanpi.cowtransfer.com/s/48f51cc100844b",target:"_blank",rel:"noopener noreferrer"},I=i(`<p>修改export.py函数</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>parser.add_argument(&#39;--data&#39;, type=str, default=ROOT / &#39;data/data.yaml&#39;, help=&#39;dataset.yaml path&#39;)
parser.add_argument(&#39;--weights&#39;, type=str, default=ROOT / &#39;runs/train/exp7/weights/best.pt&#39;, help=&#39;weights path&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/canaan-docs/image-20230629103642324.png" alt="image-20230629103642324"></p><p>打开Conda终端，激活yolov5环境配置后，进入源码目录，如下所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>(base) C:\\Users\\100askTeam&gt;conda activate py37_yolov5

(py37_yolov5) C:\\Users\\100askTeam&gt;D:

(py37_yolov5) D:\\&gt;cd D:\\Programmers\\ModelDeployment\\2.yolov5\\yolov5-6.0

(py37_yolov5) D:\\Programmers\\ModelDeployment\\2.yolov5\\yolov5-6.0&gt;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在conda终端输入：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>python export.py --include onnx --dynamic
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/canaan-docs/image-20230629104014942.png" alt="image-20230629104014942"></p><p>导出的模型会与输入的模型位于同一路径下，假设我输入的模型位于：<code>runs\\train\\exp7\\weights</code></p><p><img src="http://photos.100ask.net/canaan-docs/image-20230629104123779.png" alt="image-20230629104123779"></p><h3 id="_2-1-简化模型" tabindex="-1"><a class="header-anchor" href="#_2-1-简化模型" aria-hidden="true">#</a> 2.1 简化模型</h3><p>简化命令如下：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>python -m onnxsim &lt;输入模型&gt; &lt;输出模型&gt; --input-shape &lt;输入图像尺寸&gt;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>例如：</p><p>输入模型路径为runs/train/exp7/weights/best.onnx，输出模型路径为runs/train/exp7/weights/best-sim.onnx</p><p>输入图像尺寸固定为320x320。</p><p>​ 在conda终端输入以下命令：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>python -m onnxsim runs/train/exp7/weights/best.onnx runs/train/exp7/weights/best-sim.onnx --overwrite-input-shape 1,3,320,320
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>执行结果如下图所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>(py37_yolov5) D:\\Programmers\\ModelDeployment\\2.yolov5\\yolov5-6.0&gt;python -m onnxsim runs/train/exp7/weights/best.onnx runs/train/exp7/weights/best-sim.onnx --overwrite-input-shape 1,3,320,320
Simplifying...
Finish! Here is the difference:
┌────────────┬────────────────┬──────────────────┐
│            │ Original Model │ Simplified Model │
├────────────┼────────────────┼──────────────────┤
│ Add        │ 7              │ 7                │
│ Concat     │ 13             │ 13               │
│ Conv       │ 60             │ 60               │
│ MaxPool    │ 3              │ 3                │
│ Mul        │ 57             │ 57               │
│ Resize     │ 2              │ 2                │
│ Sigmoid    │ 60             │ 60               │
│ Model Size │ 27.6MiB        │ 27.6MiB          │
└────────────┴────────────────┴──────────────────┘
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>执行完成后可以在YOLOV5-V6.0源码目录下看到名称为<code>best-sim.onnx</code>文件，请保存好该文件，后续我们可以使用该文件转换为K510芯片内置的KPU的kmodel文件。</p><h3 id="_2-2-查看模型" tabindex="-1"><a class="header-anchor" href="#_2-2-查看模型" aria-hidden="true">#</a> 2.2 查看模型</h3>`,22),w={href:"https://netron.app/",target:"_blank",rel:"noopener noreferrer"},P={href:"https://netron.app/",target:"_blank",rel:"noopener noreferrer"},M=a("code",null,"Opne Model",-1),A=i(`<p><img src="http://photos.100ask.net/canaan-docs/image-20230728162924747.png" alt="image-20230728162924747"></p><p>点击<code>Open Model</code>之后会弹出文件管理器，我们需要进入YOLOV5-V6.0源码目录下选中刚刚我们简化后的<code>best-sim.onnx</code>模型文件后，点击打开即可。</p><p>选择刚刚生成的模型文件后，网站会帮我们自动加载模型文件，加载完成后如下图所示：</p><p><img src="http://photos.100ask.net/canaan-docs/image-20230728163832832.png" alt="image-20230728163832832"></p><p>我们点击<code>image</code>可以看到网络的输入输出情况。</p><p><img src="http://photos.100ask.net/canaan-docs/image-20230728163924869.png" alt="image-20230728163924869"></p><h3 id="_2-3-模型转换" tabindex="-1"><a class="header-anchor" href="#_2-3-模型转换" aria-hidden="true">#</a> 2.3 模型转换</h3><p>​ 模型转换这里使用需要使用到您搭建好的虚拟机环境，进入Ubuntu20.04系统中，在Home目录中打开终端，输入<code>ls</code></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~$ ls
Desktop    Downloads  Pictures  Templates  x86_64
Documents  Music      Public    Videos     yolov5s-modelTransformation
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>可以看到<code>yolov5s-modelTransformation</code>文件夹，该文件夹是我们给您提供的yolov5转换模型示例。进入该文件夹</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~$ cd yolov5s-modelTransformation/
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>将您的<code>best-sim.onnx</code>模型文件传入虚拟机中的<code>yolov5s-modelTransformation</code>目录下，如下所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~/yolov5s-modelTransformation$ ls
gen_yolov5s_320_with_sigmoid_bf16_with_preprocess_output_nhwc.py
requirements.txt
yolov5s-sim.onnx
best-sim.onnx
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>执行<code>gen_yolov5s_320_with_sigmoid_bf16_with_preprocess_output_nhwc.py</code>程序，将onnx模型文件转换为kmodel模型文件</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>python gen_yolov5s_320_with_sigmoid_bf16_with_preprocess_output_nhwc.py --target k510   --dump_dir ./tmp --onnx ./best-sim.onnx --kmodel ./best-sim.kmodel
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>注意上述命令中</p><ul><li>--target：目标板子芯片，我们使用的K510，需要填K510。</li><li>--onnx：为输入模型的路径，可自定义名称，文件格式为onnx。</li><li>--dump_dir：临时文件存放位置，会自动在当前目录创建。</li><li>./yolov5s-sim.kmodel：为输出模型的路径，可自定义名称，文件格式为kmodel。</li></ul><p>转换完成后会在当前目录下生成对应kmodel模型文件，输入<code>ls</code>查看：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>best-sim.onnxubuntu@ubuntu2004:~/yolov5s-modelTransformation$ ls
gen_yolov5s_320_with_sigmoid_bf16_with_preprocess_output_nhwc.py
requirements.txt
yolov5s-sim.kmodel
yolov5s-sim.onnx
best-sim.onnx
best-sim.kmodel
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>将<code>best-sim.kmodel</code>拷贝到TF卡中备用，后续用于开发板端的模型部署。</p><h2 id="_3-修改和编译ai应用程序" tabindex="-1"><a class="header-anchor" href="#_3-修改和编译ai应用程序" aria-hidden="true">#</a> 3.修改和编译AI应用程序</h2><blockquote><p>开始前请确保您已经阅读《AI应用程序编译》，并搭建好了虚拟机和获取AI应用源码以及工具链。</p></blockquote><p>​ 启动您配置好环境和AI应用开发的虚拟机Ubuntu20.04，启动完成后打开串口终端，进入AI应用程序源码目录</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~$ cd DongshanPI-Vision_AI-APP/code/
ubuntu@ubuntu2004:~/DongshanPI-Vision_AI-APP/code$ ls
build.sh             common           gc2053.conf              imx219_1.conf         Makefile            self_learning                 video_object_detect_320x320.conf
cmake                face_alignment   gc2093.conf              imx385_2frame.conf    object_detect       shell                         video_object_detect_432x368.conf
CMakeCache.txt       face_detect      hand_image_classify      imx385_3frame.conf    object_detect_demo  simple_pose                   video_object_detect_480x640.conf
CMakeFiles           face_expression  head_pose_estimation     imx385_normal.conf    openpose            tmp                           video_object_detect_512.conf
cmake_install.cmake  face_landmarks   imx219_0.conf            install_manifest.txt  person_detect       video_192x320.conf            video_object_detect_640.conf
CMakeLists.txt       face_recog       imx219_1080x1920_0.conf  license_plate_recog   retinaface_mb_320   video_object_detect_320.conf  video_object_detect_640x480.conf
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_3-1-修改目标检测源码" tabindex="-1"><a class="header-anchor" href="#_3-1-修改目标检测源码" aria-hidden="true">#</a> 3.1 修改目标检测源码</h3><p>​ yolov5目标检测源码目录中</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~/DongshanPI-Vision_AI-APP/code$ cd object_detect
ubuntu@ubuntu2004:~/DongshanPI-Vision_AI-APP/code/object_detect$ ls
CMakeFiles           cv2_utils.cc  Makefile          object_detect.h
cmake_install.cmake  cv2_utils.h   object_detect     README.md
CMakeLists.txt       main.cc       object_detect.cc
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>​ 使用vi编辑器，修改<code>object_detect.h</code>头文件。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~/DongshanPI-Vision_AI-APP/code/object_detect$ vi object_detect.h
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>打开程序后需要修改以下三个地方:</p><ul><li>类别数</li><li>标签名</li><li>先验框</li></ul><h4 id="_3-1-1-修改类别数" tabindex="-1"><a class="header-anchor" href="#_3-1-1-修改类别数" aria-hidden="true">#</a> 3.1.1 修改类别数</h4><p>​ 在<code>object_detect.h</code>头文件程序中，找到宏定义<code>CLASS_NUM</code>，原本yolov5的目标检测类别数为80，宏定义如下所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>#define CLASS_NUM                   80
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/canaan-docs/image-20230803110011035.png" alt="image-20230803110011035"></p><p>我们需要将参数80，修改为您自己训练模型的类别数。您可以查看YOLOV5-V6.0源码中的定义，这里以我之前训练的源码为例，打开源码目录下的data文件夹下的data.yaml文件，如下图所示：</p><p><img src="http://photos.100ask.net/canaan-docs/image-20230803105332567.png" alt="image-20230803105332567"></p><p>可以查看data.yaml文件中的<code>nc</code>类别数为3。可能您训练的模型类别数不一样，请以您实际的为准。</p><p><img src="http://photos.100ask.net/canaan-docs/image-20230803105539182.png" alt="image-20230803105539182"></p><p>我们获得模型的训练类别数后，将该参数传入宏定义<code>#define CLASS_NUM </code>中</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>#define CLASS_NUM                   3
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/canaan-docs/image-20230803105932531.png" alt="image-20230803105932531"></p><h4 id="_3-1-2-修改标签名" tabindex="-1"><a class="header-anchor" href="#_3-1-2-修改标签名" aria-hidden="true">#</a> 3.1.2 修改标签名</h4><p>​ 在<code>object_detect.h</code>头文件程序中，找到<code>objectDetectvector</code>类中容器<code>std::vector&lt;std::string&gt; labels</code>，vector容器定义如下所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>std::vector&lt;std::string&gt; labels
    {
        &quot;person&quot;, &quot;bicycle&quot;, &quot;car&quot;, &quot;motorcycle&quot;, &quot;airplane&quot;, &quot;bus&quot;, &quot;train&quot;, &quot;truck&quot;,
        &quot;boat&quot;, &quot;traffic light&quot;, &quot;fire hydrant&quot;, &quot;stop sign&quot;, &quot;parking meter&quot;, &quot;bench&quot;, &quot;bird&quot;, &quot;cat&quot;,
        &quot;dog&quot;, &quot;horse&quot;, &quot;sheep&quot;, &quot;cow&quot;, &quot;elephant&quot;, &quot;bear&quot;, &quot;zebra&quot;, &quot;giraffe&quot;,
        &quot;backpack&quot;, &quot;umbrella&quot;, &quot;handbag&quot;, &quot;tie&quot;, &quot;suitcase&quot;, &quot;frisbee&quot;, &quot;skis&quot;, &quot;snowboard&quot;,
        &quot;sports ball&quot;, &quot;kite&quot;, &quot;baseball bat&quot;, &quot;baseball glove&quot;, &quot;skateboard&quot;, &quot;surfboard&quot;, &quot;tennis racket&quot;, &quot;bottle&quot;,
        &quot;wine glass&quot;, &quot;cup&quot;, &quot;fork&quot;, &quot;knife&quot;, &quot;spoon&quot;, &quot;bowl&quot;, &quot;banana&quot;, &quot;apple&quot;,
        &quot;sandwich&quot;, &quot;orange&quot;, &quot;broccoli&quot;, &quot;carrot&quot;, &quot;hot dog&quot;, &quot;pizza&quot;, &quot;donut&quot;, &quot;cake&quot;,
        &quot;chair&quot;, &quot;couch&quot;, &quot;potted plant&quot;, &quot;bed&quot;, &quot;dining table&quot;, &quot;toilet&quot;, &quot;tv&quot;, &quot;laptop&quot;,
        &quot;mouse&quot;, &quot;remote&quot;, &quot;keyboard&quot;, &quot;cell phone&quot;, &quot;microwave&quot;, &quot;oven&quot;, &quot;toaster&quot;, &quot;sink&quot;,
        &quot;refrigerator&quot;, &quot;book&quot;, &quot;clock&quot;, &quot;vase&quot;, &quot;scissors&quot;, &quot;teddy bear&quot;, &quot;hair drier&quot;, &quot;toothbrush&quot;
    };
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/canaan-docs/image-20230803110429680.png" alt="image-20230803110429680"></p><p>可以看到这里总共有80个标签名，需要将容器中的标签名修改为您之前自定义训练模型的中的标签名。这里以我之前训练的为例。查看yolov5项目源码目录中data目录下的data.yaml文件。</p><p><img src="http://photos.100ask.net/canaan-docs/image-20230803110745496.png" alt="image-20230803110745496"></p><p>可以从上图中找到names中的标签名，我们需要将这里定义的标签名顺序，填写到<code>std::vector&lt;std::string&gt; labels</code>容器中，如下所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>std::vector&lt;std::string&gt; labels
    {
        &quot;T113&quot;, &quot;K510&quot;, &quot;V853&quot;
    };
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/canaan-docs/image-20230803111221682.png" alt="image-20230803111221682"></p><blockquote><p>注意：这里的标签名需要和您实际训练的名称一致，且顺序也需要保持一致。</p></blockquote><h4 id="_3-1-3-修改anchor先验框" tabindex="-1"><a class="header-anchor" href="#_3-1-3-修改anchor先验框" aria-hidden="true">#</a> 3.1.3 修改Anchor先验框</h4><p>​ 在<code>object_detect.h</code>头文件程序中，找到宏定义<code>ANCHOR_NUM</code>和<code>anchors_0</code>/<code>anchors_1</code>/<code>anchors_2</code>，</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>#define ANCHOR_NUM                  3
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>float anchors_0[ANCHOR_NUM][2] = { { 10, 13 }, { 16, 30 }, { 33, 23 } };
float anchors_1[ANCHOR_NUM][2] = { { 30, 61 }, { 62, 45 }, { 59, 119 } };
float anchors_2[ANCHOR_NUM][2] = { { 116, 90 }, { 156, 198 }, { 373, 326 } };
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在目标检测源码中会把先验框分为三层，这些参数可以从您的模型配置文件中获得。这里以我之前训练的模型为例，我没有对anchors进行修改，但有些客户会对anchor进行修改。</p><p><img src="http://photos.100ask.net/canaan-docs/image-20230803111954955.png" alt="image-20230803111954955"></p><p>可以看到上图红框中的anchors有3层，分别为：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>我们需要将上述参数填入宏定义<code>ANCHOR_NUM</code>和<code>anchors_0</code>/<code>anchors_1</code>/<code>anchors_2</code>中。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>#define ANCHOR_NUM                  3
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>float anchors_0[ANCHOR_NUM][2] = { { 10, 13 }, { 16, 30 }, { 33, 23 } };
float anchors_1[ANCHOR_NUM][2] = { { 30, 61 }, { 62, 45 }, { 59, 119 } };
float anchors_2[ANCHOR_NUM][2] = { { 116, 90 }, { 156, 198 }, { 373, 326 } };
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/canaan-docs/image-20230803112458451.png" alt="image-20230803112458451"></p><p><img src="http://photos.100ask.net/canaan-docs/image-20230803112522122.png" alt="image-20230803112522122"></p><blockquote><p>注意：填入的anchors参数请确保与您自定义模型的配置参数一致。</p></blockquote><h3 id="_3-2-编译ai应用程序" tabindex="-1"><a class="header-anchor" href="#_3-2-编译ai应用程序" aria-hidden="true">#</a> 3.2 编译AI应用程序</h3><p>​ 编译前需要先配置环境变量，请进入<code>DongshanPI-Vision_AI-APP/code</code>目录下</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~/DongshanPI-Vision_AI-APP/code/object_detect$ cd ../
ubuntu@ubuntu2004:~/DongshanPI-Vision_AI-APP/code$ ls
build.sh             common           gc2053.conf              imx219_1.conf         Makefile            self_learning                 video_object_detect_320x320.conf
cmake                face_alignment   gc2093.conf              imx385_2frame.conf    object_detect       shell                         video_object_detect_432x368.conf
CMakeCache.txt       face_detect      hand_image_classify      imx385_3frame.conf    object_detect_demo  simple_pose                   video_object_detect_480x640.conf
CMakeFiles           face_expression  head_pose_estimation     imx385_normal.conf    openpose            tmp                           video_object_detect_512.conf
cmake_install.cmake  face_landmarks   imx219_0.conf            install_manifest.txt  person_detect       video_192x320.conf            video_object_detect_640.conf
CMakeLists.txt       face_recog       imx219_1080x1920_0.conf  license_plate_recog   retinaface_mb_320   video_object_detect_320.conf  video_object_detect_640x480.conf
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>激活<code>build.sh</code>环境脚本程序，输入<code>source build.sh</code> ，如下所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~/DongshanPI-Vision_AI-APP/code$ source build.sh 
-- Configuring done
-- Generating done
-- Build files have been written to: /home/ubuntu/DongshanPI-Vision_AI-APP/code
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输入<code>make clean</code>，清理一下之前编译的应用程序</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~/DongshanPI-Vision_AI-APP/code$ make clean
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>编译应用程序，输入<code>make</code></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~/DongshanPI-Vision_AI-APP/code$ make -j32
[  1%] Building CXX object face_detect/CMakeFiles/face_detect.dir/main.cc.o
[  2%] Building CXX object face_detect/CMakeFiles/face_detect.dir/cv2_utils.cc.o
[  2%] Building CXX object face_detect/CMakeFiles/face_detect.dir/anchors_320.cc.o
[  3%] Building CXX object face_detect/CMakeFiles/face_detect.dir/anchors_640.cc.o
[  5%] Building C object face_detect/CMakeFiles/face_detect.dir/__/common/k510_drm.c.o
[  4%] Building CXX object face_detect/CMakeFiles/face_detect.dir/retinaface.cc.o
[  6%] Building C object face_detect/CMakeFiles/face_detect.dir/__/common/v4l2.c.o
[  7%] Building CXX object face_detect/CMakeFiles/face_detect.dir/__/common/buf_mgt.cc.o
[  5%] Building CXX object face_landmarks/CMakeFiles/face_landmarks.dir/main.cc.o
[  8%] Building CXX object face_landmarks/CMakeFiles/face_landmarks.dir/anchors_320.cc.o
[  8%] Building CXX object face_landmarks/CMakeFiles/face_landmarks.dir/cv2_utils.cc.o
[  9%] Building CXX object object_detect/CMakeFiles/object_detect.dir/main.cc.o
[ 10%] Building CXX object object_detect/CMakeFiles/object_detect.dir/cv2_utils.cc.o
[ 12%] Building CXX object face_landmarks/CMakeFiles/face_landmarks.dir/anchors_640.cc.o
[ 12%] Building CXX object object_detect/CMakeFiles/object_detect.dir/object_detect.cc.o
[ 12%] Building C object object_detect/CMakeFiles/object_detect.dir/__/common/k510_drm.c.o
...
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>等待编译完成后，安装应用程序到tmp目录下，输入<code>make install</code></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~/DongshanPI-Vision_AI-APP/code$ make install
[  7%] Built target face_detect
[ 14%] Built target face_landmarks
[ 19%] Built target object_detect
...
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>等待安装完成后，进入<code>tmp/app/ai/exe/</code>目录下可以看到新编译出来的<code>object_detect</code></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ubuntu@ubuntu2004:~/DongshanPI-Vision_AI-APP/code$ cd tmp/app/ai/exe/
ubuntu@ubuntu2004:~/DongshanPI-Vision_AI-APP/code/tmp/app/ai/exe$ ls
face_alignment   face_recog            imx219_1080x1920_0.conf  object_detect_demo  self_learning                 video_object_detect_320x320.conf  video_object_detect_640.conf
face_detect      hand_image_classify   imx219_1.conf            openpose            simple_pose                   video_object_detect_432x368.conf  video_object_detect_640x480.conf
face_expression  head_pose_estimation  license_plate_recog      person_detect       video_192x320.conf            video_object_detect_480x640.conf
face_landmarks   imx219_0.conf         object_detect            retinaface_mb_320   video_object_detect_320.conf  video_object_detect_512.conf
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>将新编译出来的<code>object_detect</code>拷贝到TF卡中备用。</p><h2 id="_4-运行自定义模型目标检测" tabindex="-1"><a class="header-anchor" href="#_4-运行自定义模型目标检测" aria-hidden="true">#</a> 4.运行自定义模型目标检测</h2>`,81),D={href:"https://canaan-docs.100ask.net/Basic/DongshanPI-Vision/02-QuickStart.html",target:"_blank",rel:"noopener noreferrer"},V=i(`<p>等待启动完成成后，系统会自动运行摄像头实时预览程序，如下所示：</p><p><img src="http://photos.100ask.net/canaan-docs/image-20230801154016298.png" alt="image-20230801154016298"></p><p>手动结束摄像头实时预览程序，输入<code>ps</code>，查看进程及进程号。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>[root@canaan ~ ]$ ps
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>假设查看的进程号如下所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>190 root      0:02 ./v4l2_drm.out -f video_drm_1920x1080.conf -e 1 -s
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>输入以下命令结束进程</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>kill -9 190
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>结束进程后，显示屏会变为白屏，刷新屏幕的摄像头数据。</p><h3 id="_4-1-模型准备" tabindex="-1"><a class="header-anchor" href="#_4-1-模型准备" aria-hidden="true">#</a> 4.1 模型准备</h3><p>​ 将从虚拟机拷贝出来的kmodel模型文件从TF卡中拷贝到系统的<code>/app/ai/kmodel/kmodel_release/object_detect/yolov5s_320/</code>目录下，这个目录是用于存放yolov5的输入分辨率为320*320的模型文件。</p><p>​ 输入<code>ls</code>，查看该路径下的模型文件。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>[root@canaan ~ ]$ ls /app/ai/kmodel/kmodel_release/object_detect/yolov5s_320/
yolov5s_320_sigmoid_bf16_with_preprocess_output_nhwc.kmodel
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>​ 进入sd卡目录中，输入<code>cd sd/p1/</code>。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>[root@canaan ~ ]$ cd sd/p1/
[root@canaan ~/sd/p1 ]$ ls
System Volume Information object_detect
best-sim.kmodel
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>​ 将<code>best-sim.kmodel</code>模型文件拷贝到<code>/app/ai/kmodel/kmodel_release/object_detect/yolov5s_320/</code>目录下，输入</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>cp best-sim.kmodel /app/ai/kmodel/kmodel_release/object_detect/yolov5s_320/
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>查看该路径下的模型文件为：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>[root@canaan ~/sd/p1 ]$ ls /app/ai/kmodel/kmodel_release/object_detect/yolov5s_3
20/
best-sim.kmodel
yolov5s_320_sigmoid_bf16_with_preprocess_output_nhwc.kmodel
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-2-应用程序准备" tabindex="-1"><a class="header-anchor" href="#_4-2-应用程序准备" aria-hidden="true">#</a> 4.2 应用程序准备</h3><p>​ 将从虚拟机拷贝出来的ai应用程序文件从TF卡中拷贝到系统的<code>/app/ai/kmodel/kmodel_release/object_detect/yolov5s_320/</code>目录下，将<code>object_detect</code>模型文件拷贝到<code>/app/ai/exe/</code>目录下，输入</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>[root@canaan ~/sd/p1 ]$ cp object_detect /app/ai/exe/
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="_4-3-修改程序脚本文件" tabindex="-1"><a class="header-anchor" href="#_4-3-修改程序脚本文件" aria-hidden="true">#</a> 4.3 修改程序脚本文件</h3><p>​ 拷贝完成后，进入/app/ai/shell/目录下，可以看到<code>object_detect.sh</code>脚本文件。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>[root@canaan ~/sd/p1 ]$ cd /app/ai/shell/
[root@canaan /app/ai/shell ]$ ls
face_alignment.sh            object_detect_demo_bf16.sh
face_detect.sh               object_detect_demo_uint8.sh
face_expression.sh           open_pose.sh
face_landmarks.sh            person_detect.sh
face_recog.sh                retinaface_mb_320_bf16.sh
hand_image_classify.sh       retinaface_mb_320_uint8.sh
head_pose_estimation.sh      self_learning.sh
license_recog.sh             simple_pose.sh
object_detect.sh
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>​ 修改<code>object_detect.sh</code>脚本文件，该脚本用于执行yolov5目标检测程序，输入<code>vi object_detect.sh</code>，使用vi编辑器修改。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>[root@canaan /app/ai/shell ]$ vi object_detect.sh
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>输入后进入vi编辑器，输入i进行文本的编辑,将原本使用的模型修改为您新拷贝到开发板端的模型文件。修改后的内容如下所示：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>#!/bin/sh

devmem 0x970E00fc 32 0x0fffff00
devmem 0x970E0100 32 0x000000ff
devmem 0x970E00f4 32 0x00550000

cd ../exe &amp;&amp; ./object_detect ../kmodel/kmodel_release/object_detect/yolov5s_320/best-sim.kmodel 320 240 320 0.5 0.45 ./video_object_detect_320.conf  1 0 None
# cd ../exe &amp;&amp; ./object_detect ../kmodel/kmodel_release/object_detect/yolov5s_320/yolov5s_320_sigmoid_bf16_with_preprocess_output_nhwc.kmodel 320 240 320 0.5 0.45 ./video_object_detect_320.conf  1 0 None
# cd ../exe &amp;&amp; ./object_detect ../kmodel/kmodel_release/object_detect/yolov5s_640/yolov5s_640_sigmoid_bf16_with_preprocess_output_nhwc.kmodel 640 480 640 0.5 0.45 ./video_object_detect_640.conf  1 0 None
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="http://photos.100ask.net/canaan-docs/image-20230803115315488.png" alt="image-20230803115315488"></p><p>修改完成后，按下esc后，输入<code>:wq</code>。保存并退出vi编辑器。</p><h3 id="_4-4-运行yolov5目标检测" tabindex="-1"><a class="header-anchor" href="#_4-4-运行yolov5目标检测" aria-hidden="true">#</a> 4.4 运行yolov5目标检测</h3><p>​ 当您进行完成上述操作后，在<code>/app/ai/shell/</code>目录下执行<code>./object_detect.sh</code></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>[root@canaan /app/ai/shell ]$ ./object_detect.sh
[root@canaan /app/ai/shell ]$ ./object_detect.sh
case ./object_detect build May 31 2023 02:18:22
drm: Found plane_id: 50 connector_id: 49 crtc_id: 57
drm: 1080x1920 (68mm X 121mm) pixel format NV12
screen resolution: 1080x1920
drm: Found plane_id: 50 connector_id: 49 crtc_id: 57
drm: 1080x1920 (68mm X 121mm) pixel format NV12
----------------drm_setup_buffers ---------------------------------
mediactl_init:auto.conf
dofile_video_cfg:auto.conf
doit_video_cfg:start
doit_video_cfg:video5_pitch 0x10a980
...
============&gt; interp_od.load_model finished!
[   38.590373] Isp2K YUV Gamma TABLE config done!
[   38.594855] k510-isp 92600000.isp1: k510isp_pipeline_enable:end
[   38.716646] k510-isp 92600000.isp1: k510isp_video_streamon:start
[   38.722881] k510-isp 92600000.isp1: k510isp_video_check_format:start
[   38.729261] k510-isp 92600000.isp1: k510isp_video_get_graph_data:start
[   38.736361] k510-isp 92600000.isp1: k510isp_video_check_external_subdevs:start
[   38.743930] k510-isp 92600000.isp1: k510isp_pipeline_set_stream:state(1)
[   38.751276] k510-isp 92600000.isp1: k510isp_pipeline_enable:i(0)ret(0)
[   38.757831] k510-isp 92600000.isp1: k510isp_pipeline_enable:f2k cur_video(0000000074d67c92) f2k_used[0] (1)
[   38.767999] k510-isp 92600000.isp1: k510isp_pipeline_enable:i(0) f2k_used[0] (1)f2k multivideo!
[   38.776942] k510-isp 92600000.isp1: k510isp_pipeline_enable:end
total took 178.541 ms
total took 66.8472 ms
total took 66.6512 ms
total took 68.8224 ms
total took 67.9712 ms
total took 68.0848 ms
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>执行完成后，可以正常在显示屏上实时预览yolov5自定义模型目标检测。</p>`,35);function O(L,N){const t=s("ExternalLinkIcon");return o(),l("div",null,[r,a("ul",null,[a("li",null,[e("Anaconda（python 包管理工具）："),a("a",u,[e("https://www.anaconda.com/"),n(t)])]),a("li",null,[e("PyCharm社区版（免费的python IDE）："),a("a",m,[e("https://www.jetbrains.com/pycharm/"),n(t)])]),a("li",null,[e("labelImg数据标注工具："),a("a",p,[e("https://github.com/heartexlabs/labelImg/releases"),n(t)])])]),v,a("ul",null,[a("li",null,[e("训练自定义模型：需要使用原始的"),a("a",b,[e("yolov5-v6.0源码"),n(t)]),e("进行训练。")]),a("li",null,[e("导出模型：需要修改模型程序文件（修改后可能无法进行训练），修改后源码下载地址："),a("a",_,[e("yolov5-v6.0-K510"),n(t)]),e(" 。")])]),h,g,a("p",null,[e("​ 如果需要训练自定义模型，肯定需要手动去标注图像，获取图像中对应的label位置信息。这里我们使用LabelImg，它是用Python编写的，图形界面使用QT，是灵活的开源数据标注工具。数据标注工具下载地址："),a("a",x,[e("LabelImg-windows_v1.8.1.zip"),n(t)])]),f,a("p",null,[e("下面为LabelImg"),a("a",k,[e("快捷键目录"),n(t)]),e("：")]),q,a("p",null,[e("​ 在训练前，我们上一章节备份了一份源码，我们需要在没有修改原始网络的源码里进行训练，否则您可以遇到不可预知的错误。如果您没有进行备份也可重新下载："),a("a",y,[e("https://dongshanpi.cowtransfer.com/s/a8d5f9b4faec4c"),n(t)])]),j,a("p",null,[e("​ 导出模型需要使用上一小节修改后的yolov5-v6.0源码，如果您不想进行修改，可直接使用我们提供的修改好的源码，下载地址："),a("a",C,[e("yolov5-v6.0-K510"),n(t)]),e(" 。")]),I,a("p",null,[e("使用"),a("a",w,[e("netron"),n(t)]),e("工具查看网络模型，该工具是一个在线的深度学习模型可视化工具，我们可以使用该工具查看神经网络模型。这里简单演示如何查看我们刚刚生成的模型。使用浏览器打开"),a("a",P,[e("https://netron.app/"),n(t)]),e("网站，打开后出现如下界面，点击红框处的"),M,e("打开需要查看的模型文件。")]),A,a("p",null,[e("​ 启动前请先按"),a("a",D,[e("《快速启动》"),n(t)]),e("中连接好两个MIPI摄像头、MIPI显示屏后，将TF卡插入开发板端。将拨码开关拨至EMMC启动，使用两条Type-C数据线连接开发板端和电脑端的USB3.0口后，可看到开发板端正常启动。")]),V])}const F=d(c,[["render",O],["__file","08-DeployCustomYolov5Model.html.vue"]]);export{F as default};
